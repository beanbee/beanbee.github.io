<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Beanbee&#39;s Blog</title>
  
  
  <link href="https://beanbee.github.io/blog/atom.xml" rel="self"/>
  
  <link href="https://beanbee.github.io/"/>
  <updated>2022-08-10T09:31:35.023Z</updated>
  <id>https://beanbee.github.io/</id>
  
  <author>
    <name>Ian</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>合并K个升序数组</title>
    <link href="https://beanbee.github.io/blog/2022/lc-merge-k-sorted-arrays/"/>
    <id>https://beanbee.github.io/blog/2022/lc-merge-k-sorted-arrays/</id>
    <published>2022-06-12T04:31:05.000Z</published>
    <updated>2022-08-10T09:31:35.023Z</updated>
    
    <content type="html"><![CDATA[<p>面试题，原型为Leetcode <a href="https://leetcode-cn.com/problems/merge-k-sorted-lists/">23. 合并K个升序链表</a> ，这是是要求合并K个升序数组，返回结果数组。</p><h2 id="思路"><a href="#思路" class="headerlink" title="思路"></a>思路</h2><p>本题解法较多，比如合并快排，依次合并两个数组，heap sort；介于数组的原因，综合考虑时间和空间复杂度用heap来解决更容易。</p><ol><li>构建小顶堆minHeap，存储每个数组的第一个元素，一共K个</li><li>每次pop heap的堆顶元素，同时将对应元素所在数组的下一个push heap</li><li>依次pop直到heap size为空</li></ol><span id="more"></span><h2 id="复杂度"><a href="#复杂度" class="headerlink" title="复杂度"></a>复杂度</h2><p>时间：小顶堆元素不超过k，插入和删除的时间代价为 O($log k$)，最多有 n 个点，每个点都插入删除各一次，总的渐进时间复杂度为 O($n×logk$)</p><p>空间：O(k) 堆最多元素为k个（忽略结果空间）</p><h2 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h2><p>小顶堆的实现直接引用：<a href="https://pkg.go.dev/container/heap#example-package-PriorityQueue">https://pkg.go.dev/container/heap#example-package-PriorityQueue</a></p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> <span class="string">&quot;container/heap&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">mergeKArray</span><span class="params">(arrays [][]<span class="type">int</span>)</span></span> []<span class="type">int</span> &#123;</span><br><span class="line">    k := <span class="built_in">len</span>(arrays)</span><br><span class="line">    <span class="keyword">if</span> k == <span class="number">0</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> []<span class="type">int</span>&#123;&#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// init heap</span></span><br><span class="line">    <span class="keyword">var</span> minHeap MyHeap</span><br><span class="line">    heap.Init(&amp;minHeap)</span><br><span class="line">    <span class="keyword">for</span> i := <span class="number">0</span>; i &lt; k; i++ &#123;</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(arrays[i]) &gt; <span class="number">0</span> &#123;</span><br><span class="line">            heap.Push(&amp;minHeap, &amp;Item&#123;</span><br><span class="line">                ID:      i,</span><br><span class="line">                Current: <span class="number">0</span>,</span><br><span class="line">                Num:     arrays[i][<span class="number">0</span>],</span><br><span class="line">            &#125;)</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// pop &amp; result</span></span><br><span class="line">    result := <span class="built_in">make</span>([]<span class="type">int</span>, <span class="number">0</span>)</span><br><span class="line">    <span class="keyword">for</span> minHeap.Len() &gt; <span class="number">0</span> &#123;</span><br><span class="line">        item := heap.Pop(&amp;minHeap).(*Item)</span><br><span class="line">        result = <span class="built_in">append</span>(result, item.Num)</span><br><span class="line"></span><br><span class="line">        <span class="comment">// move to next</span></span><br><span class="line">        <span class="keyword">if</span> item.Current+<span class="number">1</span> &lt; <span class="built_in">len</span>(arrays[item.ID]) &#123;</span><br><span class="line">            heap.Push(&amp;minHeap, &amp;Item&#123;</span><br><span class="line">                ID:      item.ID,</span><br><span class="line">                Current: item.Current + <span class="number">1</span>,</span><br><span class="line">                Num:     arrays[item.ID][item.Current+<span class="number">1</span>],</span><br><span class="line">            &#125;)</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> result</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 实现一个自己小顶堆，需要记录数组id和序号</span></span><br><span class="line"><span class="keyword">type</span> Item <span class="keyword">struct</span> &#123;</span><br><span class="line">    ID      <span class="type">int</span></span><br><span class="line">    Current <span class="type">int</span></span><br><span class="line">    Num     <span class="type">int</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 下面的实现基本copy自golang doc</span></span><br><span class="line"><span class="comment">// A MyHeap implements heap.Interface and holds Items.</span></span><br><span class="line"><span class="keyword">type</span> MyHeap []*Item</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(pq MyHeap)</span></span> Len() <span class="type">int</span> &#123; <span class="keyword">return</span> <span class="built_in">len</span>(pq) &#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(pq MyHeap)</span></span> Less(i, j <span class="type">int</span>) <span class="type">bool</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> pq[i].Num &lt; pq[j].Num</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(pq MyHeap)</span></span> Swap(i, j <span class="type">int</span>) &#123;</span><br><span class="line">    pq[i], pq[j] = pq[j], pq[i]</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(pq *MyHeap)</span></span> Push(x <span class="keyword">interface</span>&#123;&#125;) &#123;</span><br><span class="line">    item := x.(*Item)</span><br><span class="line">    *pq = <span class="built_in">append</span>(*pq, item)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(pq *MyHeap)</span></span> Pop() <span class="keyword">interface</span>&#123;&#125; &#123;</span><br><span class="line">    old := *pq</span><br><span class="line">    n := <span class="built_in">len</span>(old)</span><br><span class="line">    item := old[n<span class="number">-1</span>]</span><br><span class="line">    old[n<span class="number">-1</span>] = <span class="literal">nil</span> <span class="comment">// avoid memory leak</span></span><br><span class="line">    *pq = old[<span class="number">0</span> : n<span class="number">-1</span>]</span><br><span class="line">    <span class="keyword">return</span> item</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    
    <summary type="html">&lt;p&gt;面试题，原型为Leetcode &lt;a href=&quot;https://leetcode-cn.com/problems/merge-k-sorted-lists/&quot;&gt;23. 合并K个升序链表&lt;/a&gt; ，这是是要求合并K个升序数组，返回结果数组。&lt;/p&gt;
&lt;h2 id=&quot;思路&quot;&gt;&lt;a href=&quot;#思路&quot; class=&quot;headerlink&quot; title=&quot;思路&quot;&gt;&lt;/a&gt;思路&lt;/h2&gt;&lt;p&gt;本题解法较多，比如合并快排，依次合并两个数组，heap sort；介于数组的原因，综合考虑时间和空间复杂度用heap来解决更容易。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;构建小顶堆minHeap，存储每个数组的第一个元素，一共K个&lt;/li&gt;
&lt;li&gt;每次pop heap的堆顶元素，同时将对应元素所在数组的下一个push heap&lt;/li&gt;
&lt;li&gt;依次pop直到heap size为空&lt;/li&gt;
&lt;/ol&gt;</summary>
    
    
    
    <category term="codeblock" scheme="https://beanbee.github.io/categories/codeblock/"/>
    
    
    <category term="leetcode" scheme="https://beanbee.github.io/tags/leetcode/"/>
    
    <category term="interview" scheme="https://beanbee.github.io/tags/interview/"/>
    
    <category term="bytedance" scheme="https://beanbee.github.io/tags/bytedance/"/>
    
  </entry>
  
  <entry>
    <title>多个数组中和为0的组合数量</title>
    <link href="https://beanbee.github.io/blog/2022/lc-number-of-sum-zero-in-four-nums/"/>
    <id>https://beanbee.github.io/blog/2022/lc-number-of-sum-zero-in-four-nums/</id>
    <published>2022-06-11T15:13:46.000Z</published>
    <updated>2022-08-10T09:31:35.023Z</updated>
    
    <content type="html"><![CDATA[<p>一道面试题：给定四个等长的整形数组(a, b, c, d)，实现一个函数，接收这四个数组为参数，统计从每个数组数组中各自选一个数，他们的和正好为0的所有情况的数量。要求时间复杂度 &lt;&#x3D; O($n^2$)。</p><span id="more"></span><h2 id="思路"><a href="#思路" class="headerlink" title="思路"></a>思路</h2><p>如果使用暴力迭代（四层for循环）或者回溯，对应的时间复杂度都为O($n^4$)；此时借助两数之和的优化，即最后两个数组的查找操作用哈希表简化为O(n)，可实现复杂度O($n^3$)，不过仍然达不到目标O($n^2$)。</p><p>更进一步，考虑将四个数组的查找操作展开为两两合并：</p><ol><li>使用MAP记录前两个数组(a,b)元素之和的所有组合，key为两个数相加之和，value为对应和的数量</li><li>使用同样的方法合并后两个数组(c,d)，得到另一个MAP，key为两个数相加之和，value为对应和的数量</li><li>MAP1与MAP2进行[两数之和]，统计所有的次数</li></ol><h3 id="复杂度"><a href="#复杂度" class="headerlink" title="复杂度"></a>复杂度</h3><p>时间：1和2步骤都是O($n^2$)，步骤三遍历MAP1为O($n^2$)，综合复杂度为O($n^2$)</p><p>空间：使用两个map存储n*n个元素，空间复杂度O($n^2$)</p><h3 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h3><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">numberOfSumIn4</span><span class="params">(nums ...[]<span class="type">int</span>)</span></span> <span class="type">int</span> &#123;</span><br><span class="line">m1 := combineTwo(nums[<span class="number">0</span>], nums[<span class="number">1</span>])</span><br><span class="line">m2 := combineTwo(nums[<span class="number">2</span>], nums[<span class="number">3</span>])</span><br><span class="line"></span><br><span class="line"><span class="keyword">var</span> result <span class="type">int</span></span><br><span class="line"><span class="keyword">for</span> s, c1 := <span class="keyword">range</span> m1 &#123;</span><br><span class="line">target := <span class="number">0</span> - s</span><br><span class="line">c2, ok := m2[target]</span><br><span class="line"><span class="keyword">if</span> ok &#123;</span><br><span class="line">result += c1 * c2</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> result</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// combine the sums of two ints and return map[sum]count</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">combineTwo</span><span class="params">(nums1, nums2 []<span class="type">int</span>)</span></span> <span class="keyword">map</span>[<span class="type">int</span>]<span class="type">int</span> &#123;</span><br><span class="line">n, m := <span class="built_in">len</span>(nums1), <span class="built_in">make</span>(<span class="keyword">map</span>[<span class="type">int</span>]<span class="type">int</span>, <span class="number">0</span>)</span><br><span class="line"><span class="keyword">for</span> i := <span class="number">0</span>; i &lt; n; i++ &#123;</span><br><span class="line"><span class="keyword">for</span> j := <span class="number">0</span>; j &lt; n; j++ &#123;</span><br><span class="line"><span class="keyword">if</span> _, ok := m[nums1[i]+nums2[j]]; !ok &#123;</span><br><span class="line">m[nums1[i]+nums2[j]] = <span class="number">0</span></span><br><span class="line">&#125;</span><br><span class="line">m[nums1[i]+nums2[j]]++</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> m</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>还没有想出来更优的解法。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;一道面试题：给定四个等长的整形数组(a, b, c, d)，实现一个函数，接收这四个数组为参数，统计从每个数组数组中各自选一个数，他们的和正好为0的所有情况的数量。要求时间复杂度 &amp;lt;&amp;#x3D; O($n^2$)。&lt;/p&gt;</summary>
    
    
    
    <category term="codeblock" scheme="https://beanbee.github.io/categories/codeblock/"/>
    
    
    <category term="leetcode" scheme="https://beanbee.github.io/tags/leetcode/"/>
    
    <category term="interview" scheme="https://beanbee.github.io/tags/interview/"/>
    
    <category term="apple" scheme="https://beanbee.github.io/tags/apple/"/>
    
  </entry>
  
  <entry>
    <title>PXC上使用gh-ost在线变更表结构</title>
    <link href="https://beanbee.github.io/blog/2018/running-gh-ost-on-pxc/"/>
    <id>https://beanbee.github.io/blog/2018/running-gh-ost-on-pxc/</id>
    <published>2018-09-13T15:13:46.000Z</published>
    <updated>2022-08-10T09:31:35.023Z</updated>
    
    <content type="html"><![CDATA[<p>考虑到Galera Cluster<a href="https://beanbee.me/2018/08/08/did-online-ddl-work-on-pxc/#DDL-on-Galera-Cluster">处理DDL的特殊性</a>，在PXC(Percona XtraDB Cluster)在线变更表结构，可选的方案非常有限。官方是建议使用<code>pt-online-schema-changed</code>的（后面简称为<code>pt-osc</code>）。鉴于都出自Percona，<code>pt-online-schema-change</code>无疑对PXC的兼容程度最好，比如支持监控flow control状态、Multi-Master配置。</p><p>不过实际使用起来，<code>pt-osc</code>在DBA友好程度上还是差<code>gh-ost</code>一大截，<code>gh-ost</code>可以动态参数调整、cut-over postpone，这些对于操作业务繁重的线上系统来说，还是多了些退路。如果你的DB系统使用了PXC，同时又对<code>ps-osc</code>产生的触发器、写流量翻倍有巨大的担忧，不妨考虑下<code>gh-ost</code> on PXC的路线。本文将包含这种方式的使用场景和用法。</p><p>PXC上使用<code>gh-ost</code>有几点区别需要特别注意：</p><p><strong>一、有损切换</strong></p><p><code>pt-osc</code>的cut-over逻辑非常简单：<code>RENAME A TO A.OLD, B TO A</code>，这条语句可以保证新旧表在互换的时候是原子操作，即便是PXC多写模式下，RENAME也可以保证执行期间多节点数据一致；这样写入在不同Master节点上短暂阻塞后继续写向新表，对业务基本无感知。</p><p><code>gh-ost</code>相比则’复杂’不少，按照之前描述的逻辑：</p><blockquote><p>gh-ost完成cut-over只需要两个DB链接，下面以C10, C20标识，正常的写入请求标识为C1..C9, C11..C19, C21..C29。tbl为旧表，ghost表为已经schema changed的新表。</p><ol><li>C1..C9：对 <code>tbl</code> 进行正常的DML操作，包含 <code>INSERT, UPDATE, DELETE</code></li><li>C10：<code>CREATE TABLE tbl_old (id int primary key) COMMENT=&#39;magic-be-here&#39;</code></li><li>C10：<code>LOCK TABLES tbl WRITE, tbl_old WRITE</code></li><li>C11..C19：新请求，对 <code>tbl</code> 的DML操作被<code>LOCK</code>阻塞</li><li>C20: <code>RENAME TABLE tbl TO tbl_old, ghost TO tbl</code> - 该语句依旧被<code>LOCK</code>阻塞，但是在阻塞的队列中，优先级高于C11..C19, C1..C9，以及任何尝试对<code>tbl</code>DML的操作</li><li>C21..C29：新请求，期望操作<code>tbl</code>，但依旧被<code>LOCK</code>, <code>RENAME</code>阻塞</li><li>C10：通过show processlist检测到C20的<code>RENAME</code>操作已经发起（处于blocked状态）</li><li>C10：<code>DROP TABLE tbl_old</code> - <code>tbl</code>依旧被locked，所有链接仍然处于阻塞状态</li><li>C10：<code>UNLOCK TABLES</code> - <code>RENAME</code>第一个被执行，<code>ghost</code>表被提为<code>tbl</code>，紧接着C1..C9, C11..C19, C21..C29的请求直接发至”新“表<code>tbl</code></li></ol><p><em>译自：<a href="https://github.com/github/gh-ost/issues/82">https://github.com/github/gh-ost/issues/82</a></em></p></blockquote><p>注意步骤3，<code>LOCK TABLE</code>操作<a href="https://www.percona.com/doc/percona-xtradb-cluster/5.6/limitation.html">在PXC上存在限制</a>，PXC 5.7版本<code>pxc_strict_mode</code> not in [<code>PERMISSIVE</code>, <code>DISABLE</code>]上，<code>LOCK TABLE</code>是直接报错退出；除此之外，PXC本身不会复制<code>LOCK TABLE</code>语句到其他master节点，<code>gh-ost</code>也不会这么做，这就导致其他节点如果有写入，<code>gh-ost</code>的切换数据一致性无法保证。因此<code>gh-ost</code>只能用于单节点写入的PXC集群，并且不能使用<code>pxc_strict_mode</code>。</p><span id="more"></span><p>再注意看步骤8，这个切换过程中，C10需要进行<code>DROP TABLE</code>才能继续后面的unlock操作，从而保证整个切换一致，普通版本MySQL上，C10的步骤8是执行没问题的；但是在PXC上就不行，原理在<a href="https://beanbee.me/2018/08/08/did-online-ddl-work-on-pxc/#Total-Order-Isolation-TOI">上一篇文章中有描述</a>：“PXC的TOI模式下DDL必须串行执行，即使前一条DDL也是处于阻塞状态”。所以之前C20在步骤5发起过<code>RENAME TABLE</code>操作了，步骤8这里<code>DROP TABLE</code>就会被PXC阻塞，处于<code>Preparing for TO isolation</code>。结论即是<code>gh-ost</code>默认的无损切换方式不可用于PXC集群。</p><p>当然<code>gh-ost</code>还提供了个选项<code>two-step</code>，即facebook OSC的切换方式，步骤如下：</p><ol><li>C10: LOCK TABLES tbl WRITE</li><li>C20: 从binlog继续追加增量，保证tbl与ghost表一致</li><li>C10: ALTER TABLE tbl TO tbl_old;</li><li>C10: ALTER TABLE ghost TO tbl;</li><li>C10: UNLOCK TABLES;</li></ol><p>two-steps将切换方式变成了单线程两次单独的ALTER TABLE操作，很显然这种情况下，在LOCK后到新表被ghost替换之前，业务是写不到tbl表的，相当于有损切换，尽管这个时间通常是非常短暂的……</p><p>综上，<code>gh-ost</code>只能用于<strong>单节点写入</strong>、<strong>关闭pxc_strict_mode的PXC集群</strong>，**cut-over方式需要使用<code>two-step</code>**。</p><p><strong>二、限速</strong></p><p>通常用了PXC的集群，多半不会PXC master节点提供所有业务读写，master下面继续挂从库提供业务读很普遍，osc工具在执行的时候也必须考虑他们的吞吐量瓶颈。<code>gh-ost</code>和<code>pt-osc</code>都可以从多个方面来限制osc的执行速度，以下是这两个工具都提供的：</p><ol><li>max-lag: 配置允许从库延迟的时间，超过时间则暂停</li><li>max-load: 配置主库允许的最大运行连接等系统变量，超过同样暂停</li><li>chunk-size: 一次从旧表复制到新表的行数</li><li>chunk-time: 每次复制一个chunk数据到新表的时候，sleep指定的时间；</li></ol><p>限速策略上，两个工具都很全面了，尤其像<code>chunk-time</code>(gh-ost上叫做<code>nice-ratio</code>)这样的选项能够很大程度减小粗暴的<code>chunk-size</code> + <code>max-lag</code>配置引起的从库延迟。不过有一点<code>pt-osc</code>做的更好，写入过多很可能引起PXC节点之间发生flow control，<code>pt-osc</code>可以通过<code>--max-flow-ctl</code>这样的配置进行识别限速，而<code>gh-ost</code>就不行了。用<code>gh-ost</code>的话一定要注意，只能通过其他方式来避免了，比如调小<code>max-lag</code>或者增加监控。</p><p><strong>实践</strong></p><p>下面就是一个可以用的<code>gh-ost</code>操作PXC命令，已经过线上验证：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">./gh-ost \</span><br><span class="line">--max-load=Threads_running=100,Threads_connected=500 \</span><br><span class="line">--critical-load=Threads_running=200 --critical-load-interval-millis=60000 \</span><br><span class="line">--throttle-control-replicas=&quot;slave01.com,slave02.com&quot; \</span><br><span class="line">--chunk-size=100 \</span><br><span class="line">--heartbeat-interval-millis=100 \</span><br><span class="line">--max-lag-millis=10000 \</span><br><span class="line">--dml-batch-size=100 \</span><br><span class="line">--nice-ratio=0.1 \</span><br><span class="line">--port=3306 \</span><br><span class="line">--host=pxcread.com \                      # 用PXC的只读节点作为源</span><br><span class="line">--assume-master-host=pxcmaster.com \      # 最终要操作cut-over的是PXC的可写节点</span><br><span class="line">--replica-server-id=99999 \</span><br><span class="line">--database=&quot;test&quot; \</span><br><span class="line">--table=&quot;test&quot; \</span><br><span class="line">--alter=&quot;engine=innodb&quot; \</span><br><span class="line">--allow-master-master \</span><br><span class="line">--verbose \</span><br><span class="line">--switch-to-rbr \</span><br><span class="line">--cut-over=two-step \                     # 必须用two-step!!!</span><br><span class="line">--exact-rowcount \</span><br><span class="line">--concurrent-rowcount \</span><br><span class="line">--default-retries=120 \</span><br><span class="line">--skip-foreign-key-checks \               # 用ghost自然不能用外键</span><br><span class="line">--discard-foreign-keys \</span><br><span class="line">--panic-flag-file=./panic.flag \</span><br><span class="line">--postpone-cut-over-flag-file=./postpone.flag \</span><br><span class="line">--execute</span><br></pre></td></tr></table></figure><p>总结下以上的注意点：</p><blockquote><p>在PXC集群上使用<code>gh-ost</code>：</p><ol><li>PXC 5.6版本可用，或PXC 5.7 with <code>pxc_strict_mode</code> in [<code>PERMISSIVE</code>, <code>DISABLE</code>]</li><li>不支持multi-master的PXC集群，必须只能有单个节点提供写，否则数据不一致</li><li>切换方式必须使用<code>two-step</code>，使用默认的方式会直接hang死PXC集群……</li><li>无法监控flow control情况，需要单独监控或者使用更小的max-lag-millis</li><li>操作的表不能有外键和外键引用</li><li>先线下测试……</li></ol></blockquote><p>虽然<code>gh-ost</code>用起来可控性更强，动态参数也很方便，不过在PXC上还是一些限制，用起来需要DBA自己tradeoff。反过来思考，我们设计DB结构的时候应该尽可能的简单，比如triggerless, no FK，尽量避免多点写入…… 这样长期看，后续的运维代价会小很多，自然也在工具的选择上也有更大的自由度。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;考虑到Galera Cluster&lt;a href=&quot;https://beanbee.me/2018/08/08/did-online-ddl-work-on-pxc/#DDL-on-Galera-Cluster&quot;&gt;处理DDL的特殊性&lt;/a&gt;，在PXC(Percona XtraDB Cluster)在线变更表结构，可选的方案非常有限。官方是建议使用&lt;code&gt;pt-online-schema-changed&lt;/code&gt;的（后面简称为&lt;code&gt;pt-osc&lt;/code&gt;）。鉴于都出自Percona，&lt;code&gt;pt-online-schema-change&lt;/code&gt;无疑对PXC的兼容程度最好，比如支持监控flow control状态、Multi-Master配置。&lt;/p&gt;
&lt;p&gt;不过实际使用起来，&lt;code&gt;pt-osc&lt;/code&gt;在DBA友好程度上还是差&lt;code&gt;gh-ost&lt;/code&gt;一大截，&lt;code&gt;gh-ost&lt;/code&gt;可以动态参数调整、cut-over postpone，这些对于操作业务繁重的线上系统来说，还是多了些退路。如果你的DB系统使用了PXC，同时又对&lt;code&gt;ps-osc&lt;/code&gt;产生的触发器、写流量翻倍有巨大的担忧，不妨考虑下&lt;code&gt;gh-ost&lt;/code&gt; on PXC的路线。本文将包含这种方式的使用场景和用法。&lt;/p&gt;
&lt;p&gt;PXC上使用&lt;code&gt;gh-ost&lt;/code&gt;有几点区别需要特别注意：&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;一、有损切换&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;pt-osc&lt;/code&gt;的cut-over逻辑非常简单：&lt;code&gt;RENAME A TO A.OLD, B TO A&lt;/code&gt;，这条语句可以保证新旧表在互换的时候是原子操作，即便是PXC多写模式下，RENAME也可以保证执行期间多节点数据一致；这样写入在不同Master节点上短暂阻塞后继续写向新表，对业务基本无感知。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;gh-ost&lt;/code&gt;相比则’复杂’不少，按照之前描述的逻辑：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;gh-ost完成cut-over只需要两个DB链接，下面以C10, C20标识，正常的写入请求标识为C1..C9, C11..C19, C21..C29。tbl为旧表，ghost表为已经schema changed的新表。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;C1..C9：对 &lt;code&gt;tbl&lt;/code&gt; 进行正常的DML操作，包含 &lt;code&gt;INSERT, UPDATE, DELETE&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;C10：&lt;code&gt;CREATE TABLE tbl_old (id int primary key) COMMENT=&amp;#39;magic-be-here&amp;#39;&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;C10：&lt;code&gt;LOCK TABLES tbl WRITE, tbl_old WRITE&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;C11..C19：新请求，对 &lt;code&gt;tbl&lt;/code&gt; 的DML操作被&lt;code&gt;LOCK&lt;/code&gt;阻塞&lt;/li&gt;
&lt;li&gt;C20: &lt;code&gt;RENAME TABLE tbl TO tbl_old, ghost TO tbl&lt;/code&gt; - 该语句依旧被&lt;code&gt;LOCK&lt;/code&gt;阻塞，但是在阻塞的队列中，优先级高于C11..C19, C1..C9，以及任何尝试对&lt;code&gt;tbl&lt;/code&gt;DML的操作&lt;/li&gt;
&lt;li&gt;C21..C29：新请求，期望操作&lt;code&gt;tbl&lt;/code&gt;，但依旧被&lt;code&gt;LOCK&lt;/code&gt;, &lt;code&gt;RENAME&lt;/code&gt;阻塞&lt;/li&gt;
&lt;li&gt;C10：通过show processlist检测到C20的&lt;code&gt;RENAME&lt;/code&gt;操作已经发起（处于blocked状态）&lt;/li&gt;
&lt;li&gt;C10：&lt;code&gt;DROP TABLE tbl_old&lt;/code&gt; - &lt;code&gt;tbl&lt;/code&gt;依旧被locked，所有链接仍然处于阻塞状态&lt;/li&gt;
&lt;li&gt;C10：&lt;code&gt;UNLOCK TABLES&lt;/code&gt; - &lt;code&gt;RENAME&lt;/code&gt;第一个被执行，&lt;code&gt;ghost&lt;/code&gt;表被提为&lt;code&gt;tbl&lt;/code&gt;，紧接着C1..C9, C11..C19, C21..C29的请求直接发至”新“表&lt;code&gt;tbl&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;em&gt;译自：&lt;a href=&quot;https://github.com/github/gh-ost/issues/82&quot;&gt;https://github.com/github/gh-ost/issues/82&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;注意步骤3，&lt;code&gt;LOCK TABLE&lt;/code&gt;操作&lt;a href=&quot;https://www.percona.com/doc/percona-xtradb-cluster/5.6/limitation.html&quot;&gt;在PXC上存在限制&lt;/a&gt;，PXC 5.7版本&lt;code&gt;pxc_strict_mode&lt;/code&gt; not in [&lt;code&gt;PERMISSIVE&lt;/code&gt;, &lt;code&gt;DISABLE&lt;/code&gt;]上，&lt;code&gt;LOCK TABLE&lt;/code&gt;是直接报错退出；除此之外，PXC本身不会复制&lt;code&gt;LOCK TABLE&lt;/code&gt;语句到其他master节点，&lt;code&gt;gh-ost&lt;/code&gt;也不会这么做，这就导致其他节点如果有写入，&lt;code&gt;gh-ost&lt;/code&gt;的切换数据一致性无法保证。因此&lt;code&gt;gh-ost&lt;/code&gt;只能用于单节点写入的PXC集群，并且不能使用&lt;code&gt;pxc_strict_mode&lt;/code&gt;。&lt;/p&gt;</summary>
    
    
    
    <category term="workspace" scheme="https://beanbee.github.io/categories/workspace/"/>
    
    
    <category term="PXC" scheme="https://beanbee.github.io/tags/PXC/"/>
    
    <category term="Galera Cluster" scheme="https://beanbee.github.io/tags/Galera-Cluster/"/>
    
    <category term="OSC" scheme="https://beanbee.github.io/tags/OSC/"/>
    
    <category term="gh-ost" scheme="https://beanbee.github.io/tags/gh-ost/"/>
    
  </entry>
  
  <entry>
    <title>Galera Cluster能否使用Online DDL?</title>
    <link href="https://beanbee.github.io/blog/2018/did-online-ddl-work-on-pxc/"/>
    <id>https://beanbee.github.io/blog/2018/did-online-ddl-work-on-pxc/</id>
    <published>2018-08-08T03:30:38.000Z</published>
    <updated>2022-08-10T09:31:35.019Z</updated>
    
    <content type="html"><![CDATA[<p>MySQL 从5.6版本开始支持<a href="https://dev.mysql.com/doc/refman/5.6/en/innodb-create-index-overview.html">Online DDL</a>，即允许表在schema变更过程中继续让业务读写，最大程度减少部分<code>DDL</code>操作的锁表时间。Online DDL的出现给经历过MySQL老版本的人提供了极大的便利，而如果基于MySQL的PXC(Percona XtraDB Cluster)使用了5.6以上版本，能否也收益于Online DDL，加快大表变更速度呢？本文将探讨下Galera Cluster使用Online DDL可行性以及以PXC为例如何处理DDL。</p><h1 id="Online-DDL-Overview"><a href="#Online-DDL-Overview" class="headerlink" title="Online DDL Overview"></a>Online DDL Overview</h1><p>5.6版本之前，DDL执行过程是：获取<code>metadata lock</code>，全量拷贝数据至内部新表(rebuild table)，拷贝完内部互换并删除老表；整个数据拷贝期间，业务无法写表，锁表时间取决于表大小。</p><p>5.6+版本分几种类型的DDL来优化操作时间：</p><ol><li>操作只需要修改metadata，不需要拷贝全表数据；比如更改列<code>comment</code>&#x2F;<code>default value</code></li><li>操作不需要修改metadata，也不需要rebuild table；比如加二级索引</li><li>需要修改metedata+rebuild table的，则本地拷贝源表数据，拷贝完执行应用变更日志，这期间业务可写；如加列</li></ol><p>从类型上说，Online DDL只支持部分DDL，不过已能够覆盖绝大部分日常变更。无外乎加列、加索引……</p><h1 id="DDL-on-Galera-Cluster"><a href="#DDL-on-Galera-Cluster" class="headerlink" title="DDL on Galera Cluster"></a>DDL on Galera Cluster</h1><p>PXC支持多点写入，任何时刻多个节点之间表数据一致。Galera使用了<code>Certification Based Replication</code>的方式进行多节点数据同步：</p><p><img src="/images/certificationbasedreplication.png" alt="Certification Based Replication"></p><ol><li>单个节点事务提交时，将修改的事务信息以<code>write-set</code>形式广播给其他节点</li><li>其他节点收到<code>write-set</code>后，通过主键、全局ID等信息判断是否和自身已有的事务冲突</li><li>如果有一个冲突，发起提交的节点提交失败，事务回滚；否则提交成功，所有节点写入<code>write-set</code></li></ol><p>Galera集群会在事务发起之前，为每个事务分配一个全局唯一序列号，在提交时比对该序列号和最后一次成功提交之间的差值；如果这个期间有事务进行，并且和该事务主键相同，则相当于发生冲突，事务不能提交。因为其他节点发起的事务其实并不知晓这个事务，直接提交则会发生覆盖更新。这种认证方式旨在保证同样主键数据在同一事务窗口内不能在其他节点并发，从而确保数据一致。</p><p>不过该方式只针对DML，DDL的处理方法则相对”粗暴“的多。为了保证全局表的schema一致，Galera使用了特殊的方法来处理DDL，目前有TOI(default)、RSU两种模式。</p><span id="more"></span><h2 id="Total-Order-Isolation-TOI"><a href="#Total-Order-Isolation-TOI" class="headerlink" title="Total Order Isolation (TOI)"></a>Total Order Isolation (TOI)</h2><p><a href="http://galeracluster.com/documentation-webpages/schemaupgrades.html#total-order-isolation">TOI模式</a>下所有DDL操作在节点之间严格按照顺序执行，执行期间<strong>所有事务</strong>无法提交：</p><ol><li>DDL的Certification Interval永远为0。换句话说，DDL一定可以得到执行</li><li>如果执行DDL之前或期间有事务引用了相关表，无法提交：<code>ERROR 1213 (40001): Deadlock found when trying to get lock</code></li><li>执行期间发起的事务，不涉及DDL操作的表的，均会被Galera阻塞：<code>wsrep in pre-commit stage</code>状态</li><li>一旦DDL的<code>certification</code>通过，则同时在所有节点执行，DDL在对应的节点能否执行成功无法知晓</li><li>后发起的DDL操作依旧被Galera阻塞，等待上一条结束，尽管不是一张表：<code>Preparing for TO isolation</code></li></ol><p>2中有个比较难理解的点，如果一个事务在DDL之前发起了开始操作A表，理论上后面来的DDL需要等待它释放<code>metadata</code>锁才能操作，然后Galera里面则是直接让DDL开始执行，相对而言把这个先来的事务抛弃（提交时候报错<code>deadlock</code>）。这一点直接导致了Online DDL在Galera Cluster上都不可行。因为DDL之后，该表的DML事务都被Galera拒绝了，这些事务根本没机会被MySQL处理，即使MySQL的Online DDL特性支持它们继续操作这张表。而3则影响更大，所有其他的表的事务都被迫block在<code>Certification</code>层级，相当于全库锁了。</p><p>很容易在PXC上复现：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># 执行顺序：(id) <span class="number">11</span> <span class="operator">=</span><span class="operator">&gt;</span> <span class="number">12</span> <span class="operator">=</span><span class="operator">&gt;</span> <span class="number">14</span></span><br><span class="line"><span class="operator">|</span> <span class="number">11</span> <span class="operator">|</span> root <span class="operator">|</span> localhost <span class="operator">|</span> test    <span class="operator">|</span> Query <span class="operator">|</span> <span class="number">769</span> <span class="operator">|</span> altering <span class="keyword">table</span>             <span class="operator">|</span> <span class="keyword">alter</span> <span class="keyword">table</span> data1 engine<span class="operator">=</span>innodb</span><br><span class="line"><span class="operator">|</span> <span class="number">12</span> <span class="operator">|</span> root <span class="operator">|</span> localhost <span class="operator">|</span> osctest <span class="operator">|</span> Query <span class="operator">|</span> <span class="number">392</span> <span class="operator">|</span> wsrep <span class="keyword">in</span> pre<span class="operator">-</span><span class="keyword">commit</span> stage  <span class="operator">|</span> <span class="keyword">delete</span> <span class="keyword">from</span> tbl</span><br><span class="line"><span class="operator">|</span> <span class="number">14</span> <span class="operator">|</span> root <span class="operator">|</span> localhost <span class="operator">|</span> test    <span class="operator">|</span> Query <span class="operator">|</span>   <span class="number">6</span> <span class="operator">|</span> Preparing <span class="keyword">for</span> <span class="keyword">TO</span> isolation <span class="operator">|</span> <span class="keyword">create</span> <span class="keyword">table</span> tbl_new (x <span class="type">int</span>)</span><br></pre></td></tr></table></figure><h2 id="Rolling-Schema-Upgrade-RSU"><a href="#Rolling-Schema-Upgrade-RSU" class="headerlink" title="Rolling Schema Upgrade (RSU)"></a>Rolling Schema Upgrade (RSU)</h2><p><a href="http://galeracluster.com/documentation-webpages/schemaupgrades.html#rolling-schema-upgrade">RSU模式</a>提供节点之间滚动升级schema的能力，操作时：</p><ol><li>设置RSU后不执行DDL情况下不会有任何不同，节点依旧与cluster同步，继续应用<code>write-set</code></li><li>一旦发起DDL，节点与集群dsync开，数据同步停止；DDL完成后自动变回同步状态，追上增量</li><li>单节点上，DDL期间DML依旧被阻塞，行为和TOI完全一致</li><li>如果DDL时间很长，需要配置较大的<code>gcache</code>，否则做完DDL同步集群的时候发现gcache太小了强制进入SST全量恢复数据，那等于这个节点的DDL白做了……</li></ol><p>所以RSU相对TOI的主要一个区别就是DDL不会广播到其他节点进行，其他还是该阻塞的阻塞。虽然提供了滚动升级的能力，但是实际情况下，一个公司的Galera Cluster通常不会只包含multi-master，一旦某个master节点之后还有普通的MySQL复制着，这种滚动升级的难度相比普通主从MySQL架构要更高，毕竟Online DDL通过binlog复制到了从库，依旧会产生延迟……</p><h1 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h1><p>结论就是基于MySQL的Galera Cluster（比如PXC），是无法利用MySQL的Online DDL特性的。Galera处理DDL的方式即”执行“多久业务就要等待多久，所以大表变更在PXC上是非常危险的，如果需要做大表OSC，还是建议使用<code>pt-online-schema-change</code>或者<code>gh-ost</code>。</p><p>不过和5.5这样的老版本对比，使用PXC 5.6+还是能一定程度上”收益“于Online DDL。比如更改<code>default</code>值这样的操作，在5.6之前需要rebuild table，Galera会阻塞很长时间的业务；但是到了5.6版本，即使依旧block业务，但是由于只修改metadata时间极短，DDL在MySQL层面处理时间被显著加快，从而大表DDL时锁库时间也得到大幅缩短。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;MySQL 从5.6版本开始支持&lt;a href=&quot;https://dev.mysql.com/doc/refman/5.6/en/innodb-create-index-overview.html&quot;&gt;Online DDL&lt;/a&gt;，即允许表在schema变更过程中继续让业务读写，最大程度减少部分&lt;code&gt;DDL&lt;/code&gt;操作的锁表时间。Online DDL的出现给经历过MySQL老版本的人提供了极大的便利，而如果基于MySQL的PXC(Percona XtraDB Cluster)使用了5.6以上版本，能否也收益于Online DDL，加快大表变更速度呢？本文将探讨下Galera Cluster使用Online DDL可行性以及以PXC为例如何处理DDL。&lt;/p&gt;
&lt;h1 id=&quot;Online-DDL-Overview&quot;&gt;&lt;a href=&quot;#Online-DDL-Overview&quot; class=&quot;headerlink&quot; title=&quot;Online DDL Overview&quot;&gt;&lt;/a&gt;Online DDL Overview&lt;/h1&gt;&lt;p&gt;5.6版本之前，DDL执行过程是：获取&lt;code&gt;metadata lock&lt;/code&gt;，全量拷贝数据至内部新表(rebuild table)，拷贝完内部互换并删除老表；整个数据拷贝期间，业务无法写表，锁表时间取决于表大小。&lt;/p&gt;
&lt;p&gt;5.6+版本分几种类型的DDL来优化操作时间：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;操作只需要修改metadata，不需要拷贝全表数据；比如更改列&lt;code&gt;comment&lt;/code&gt;&amp;#x2F;&lt;code&gt;default value&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;操作不需要修改metadata，也不需要rebuild table；比如加二级索引&lt;/li&gt;
&lt;li&gt;需要修改metedata+rebuild table的，则本地拷贝源表数据，拷贝完执行应用变更日志，这期间业务可写；如加列&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;从类型上说，Online DDL只支持部分DDL，不过已能够覆盖绝大部分日常变更。无外乎加列、加索引……&lt;/p&gt;
&lt;h1 id=&quot;DDL-on-Galera-Cluster&quot;&gt;&lt;a href=&quot;#DDL-on-Galera-Cluster&quot; class=&quot;headerlink&quot; title=&quot;DDL on Galera Cluster&quot;&gt;&lt;/a&gt;DDL on Galera Cluster&lt;/h1&gt;&lt;p&gt;PXC支持多点写入，任何时刻多个节点之间表数据一致。Galera使用了&lt;code&gt;Certification Based Replication&lt;/code&gt;的方式进行多节点数据同步：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/images/certificationbasedreplication.png&quot; alt=&quot;Certification Based Replication&quot;&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;单个节点事务提交时，将修改的事务信息以&lt;code&gt;write-set&lt;/code&gt;形式广播给其他节点&lt;/li&gt;
&lt;li&gt;其他节点收到&lt;code&gt;write-set&lt;/code&gt;后，通过主键、全局ID等信息判断是否和自身已有的事务冲突&lt;/li&gt;
&lt;li&gt;如果有一个冲突，发起提交的节点提交失败，事务回滚；否则提交成功，所有节点写入&lt;code&gt;write-set&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Galera集群会在事务发起之前，为每个事务分配一个全局唯一序列号，在提交时比对该序列号和最后一次成功提交之间的差值；如果这个期间有事务进行，并且和该事务主键相同，则相当于发生冲突，事务不能提交。因为其他节点发起的事务其实并不知晓这个事务，直接提交则会发生覆盖更新。这种认证方式旨在保证同样主键数据在同一事务窗口内不能在其他节点并发，从而确保数据一致。&lt;/p&gt;
&lt;p&gt;不过该方式只针对DML，DDL的处理方法则相对”粗暴“的多。为了保证全局表的schema一致，Galera使用了特殊的方法来处理DDL，目前有TOI(default)、RSU两种模式。&lt;/p&gt;</summary>
    
    
    
    <category term="workspace" scheme="https://beanbee.github.io/categories/workspace/"/>
    
    
    <category term="PXC" scheme="https://beanbee.github.io/tags/PXC/"/>
    
    <category term="Online DDL" scheme="https://beanbee.github.io/tags/Online-DDL/"/>
    
    <category term="Galera Cluster" scheme="https://beanbee.github.io/tags/Galera-Cluster/"/>
    
    <category term="OSC" scheme="https://beanbee.github.io/tags/OSC/"/>
    
    <category term="RSU" scheme="https://beanbee.github.io/tags/RSU/"/>
    
  </entry>
  
  <entry>
    <title>使用PMM快速构建MySQL监控系统</title>
    <link href="https://beanbee.github.io/blog/2018/quick-manual-of-pmm-mysql/"/>
    <id>https://beanbee.github.io/blog/2018/quick-manual-of-pmm-mysql/</id>
    <published>2018-06-14T07:13:22.000Z</published>
    <updated>2022-08-10T09:31:35.023Z</updated>
    
    <content type="html"><![CDATA[<p>PMM是Percona开源的监控系统(Percona Monitoring and Management)，主要用于监控MySQL、MongoDB等数据库的性能指标，目前最新版本是1.11.0。工作原因对其进行了一段时间的调研，本文将介绍如何在生产环境使用PMM快速构建MySQL数据库监控系统，包含基本原理、部署和优缺点比较等。</p><h1 id="Architecture"><a href="#Architecture" class="headerlink" title="Architecture"></a>Architecture</h1><p>关于PMM的架构，最主要是理解它是个基于Prometheus的系统，PMM的一些组件相当于对Prometheus中各个模块的封装，架构图如下：</p><p><img src="https://www.percona.com/doc/percona-monitoring-and-management/_images/diagram.pmm-architecture.png" alt="PMM Architecture Overview"></p><p>结构分成了client-server部分：</p><ul><li>Client：包含了各种exporter的daemon，以及用于管理他们的pmm-admin命令行工具</li><li>Server - Metrics Monitor：本地存储的Prometheus、consul用于服务发现、Grafana出图；这块都是Prometheus技术栈</li><li>Server - Query Analytics：Percona自研的查询分析组件，用于分析在DB端收集的慢查询，存储于MySQL中，最终以新的datasource注册至Grafana出图展示</li><li>Server - <a href="https://github.com/github/orchestrator">Orchestrator</a>：第三方工具orchestrator，图形化展示和管理MySQL实例的复制拓扑关系</li></ul><span id="more"></span><h1 id="Deployment"><a href="#Deployment" class="headerlink" title="Deployment"></a>Deployment</h1><p>PMM的部署相对Prometheus简单不少，client和server端基本都是一键部署，维护起来也相对容易。</p><h2 id="Prerequisite"><a href="#Prerequisite" class="headerlink" title="Prerequisite"></a>Prerequisite</h2><p>系统版本CentOS7，我这里使用yum安装。建议在server和client端都添加repository：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">sudo yum install http://www.percona.com/downloads/percona-release/redhat/0.1-4/percona-release-0.1-4.noarch.rpm</span><br><span class="line">sudo yum install -y percona-toolkit</span><br><span class="line">  </span><br><span class="line"><span class="comment"># check by yum search</span></span><br><span class="line">sudo yum search percona | grep -i pmm-</span><br><span class="line">Repodata is over 2 weeks old. Install yum-cron? Or run: yum makecache fast</span><br><span class="line">pmm-client.x86_64 : Percona Monitoring and Management Client</span><br></pre></td></tr></table></figure><h3 id="Privilege"><a href="#Privilege" class="headerlink" title="Privilege"></a>Privilege</h3><p>被监控的MySQL需要为pmm-client开启对应的user权限，pmm-admin工具提供<code>--create-user</code>选项自动创建符合要求的帐号，亦可以自行创建用户：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- SUPER is necessary when running QAN agent for MySQL option modification</span></span><br><span class="line"><span class="comment">-- if you&#x27;re using orchestrator，replication client/slave are needed as well</span></span><br><span class="line"><span class="keyword">GRANT</span> <span class="keyword">SELECT</span>, PROCESS, SUPER, REPLICATION CLIENT, RELOAD <span class="keyword">ON</span> <span class="operator">*</span>.<span class="operator">*</span> <span class="keyword">TO</span> <span class="string">&#x27;pmm&#x27;</span>@<span class="string">&#x27;localhost&#x27;</span> IDENTIFIED <span class="keyword">BY</span> <span class="string">&#x27;xxx&#x27;</span> <span class="keyword">WITH</span> MAX_USER_CONNECTIONS <span class="number">10</span>;</span><br><span class="line"><span class="keyword">GRANT</span> <span class="keyword">SELECT</span>, <span class="keyword">UPDATE</span>, <span class="keyword">DELETE</span>, <span class="keyword">DROP</span> <span class="keyword">ON</span> performance_schema.<span class="operator">*</span> <span class="keyword">TO</span> <span class="string">&#x27;pmm&#x27;</span>@<span class="string">&#x27;localhost&#x27;</span>;</span><br></pre></td></tr></table></figure><h3 id="Accessibility"><a href="#Accessibility" class="headerlink" title="Accessibility"></a>Accessibility</h3><p>client与server端需要保持网络连通，否则无法完成监控数据推送和健康检查。与Prometheus相同，在不使用push-gateway的情况下，需要client与server双向互通：</p><blockquote><p><strong>Client &#x3D;&gt; Serve(80)</strong></p><p>client端使用server端Consul API, Query Analytics API, Prometheus API推送监控数据，因此这个server的80&#x2F;443端口必须对外开放</p><p><strong>Client(42000,42002…) &lt;&#x3D; Server</strong></p><p>server端需要按照一定的周期抓取client端exporter状态，比如<code>up</code>监控项</p></blockquote><p>后续可以使用<code>pmm-admin check-network</code>命令进行网络连通性检查。</p><h2 id="Launching-Server"><a href="#Launching-Server" class="headerlink" title="Launching Server"></a>Launching Server</h2><p>PMM Server提供三种方式安装，Docker、虚机实例、EC2 Image，这里说明使用Docker的安装方法，以为它更加通用和简单。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># install docker-engine if you didn&#x27;t have</span></span><br><span class="line">sudo yum install docker</span><br><span class="line">sudo systemctl start docker</span><br><span class="line"> </span><br><span class="line"><span class="comment"># pull pmm image</span></span><br><span class="line">docker pull percona/pmm-server:latest</span><br><span class="line"> </span><br><span class="line"><span class="comment"># create a container for persistent PMM data</span></span><br><span class="line">docker create \</span><br><span class="line">   -v /opt/prometheus/data \  <span class="comment"># directories inside container</span></span><br><span class="line">   -v /opt/consul-data \</span><br><span class="line">   -v /opt/mysql \</span><br><span class="line">   -v /opt/grafana \</span><br><span class="line">   --name pmm-data \</span><br><span class="line">   percona/pmm-server:latest /bin/true</span><br><span class="line">  </span><br><span class="line"><span class="comment"># create and launch the PMM Server container</span></span><br><span class="line">docker run -d \</span><br><span class="line">   -p 80:80 \</span><br><span class="line">   --volumes-from pmm-data \</span><br><span class="line">   --name pmm-server \</span><br><span class="line">   --restart always \</span><br><span class="line">   -e METRICS_RESOLUTION=5s \           <span class="comment"># collects metrics with minimum 5s resolutions</span></span><br><span class="line">   -e METRICS_RETENTION=600h \          <span class="comment"># stores time-series data for 600 hours</span></span><br><span class="line">   -e QUERIES_RETENTION=7 \             <span class="comment"># stores queries date for 7 days</span></span><br><span class="line">   -e ORCHESTRATOR_ENABLED=<span class="literal">false</span> \      <span class="comment"># disable orchestrator module</span></span><br><span class="line">   -e SERVER_USER=pmm \                 <span class="comment"># user for basic-auth</span></span><br><span class="line">   -e SERVER_PASSWORD=xxx \</span><br><span class="line">   percona/pmm-server:latest</span><br></pre></td></tr></table></figure><p>运行完以上命令使用<code>http://serverip/</code>即可进入Grafana，首页为PMM的Home Dashboard，启动会自带pmm-server的系统监控指标：</p><p><img src="/images/pmm-server-home-dashboard.png"></p><h2 id="Adding-Metrics"><a href="#Adding-Metrics" class="headerlink" title="Adding Metrics"></a>Adding Metrics</h2><p>Linux、MySQL监控都可以在client端使用pmm-admin工具添加：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># install pmm-admin</span></span><br><span class="line">sudo yum install -y pmm-client</span><br><span class="line">  </span><br><span class="line"><span class="comment"># config with pmm-server</span></span><br><span class="line">pmm-admin config --server <span class="variable">$&#123;pmm-server-ip&#125;</span> --server-user pmm --server-password xxx --client-name <span class="variable">$&#123;client_name&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># add linux metrics</span></span><br><span class="line">pmm-admin add linux:metrics --service-port=42000</span><br><span class="line">  </span><br><span class="line"><span class="comment"># add mysql metrics, disable table statistics for space saving</span></span><br><span class="line">pmm-admin add mysql:metrics --service-port=42002 -u pmm -p xxx -h localhost -P 3306 --disable-tablestats=<span class="literal">true</span></span><br><span class="line"><span class="comment"># or you want to enable table statistics on some instances</span></span><br><span class="line">pmm-admin add mysql -u pmm -p xxx --query-source=slowlog --disable-tablestats-limit=10000</span><br><span class="line"></span><br><span class="line"><span class="comment"># add remote MySQL - run it on a host which got the access to remote instance, like connecting to a RDS instance from your jump machine</span></span><br><span class="line">pmm-admin add mysql:metrics --host xxxx.rds.amazonaws.com --user pmm --password xxx --port 3306 rds-<span class="variable">$&#123;client_name&#125;</span></span><br><span class="line"> </span><br><span class="line"><span class="comment"># add Query Analytics Agent - collect slow queries</span></span><br><span class="line">pmm-admin add mysql:queries -u pmm -p xxx -h localhost -P 3306 --query-source=slowlog</span><br></pre></td></tr></table></figure><p>如果数据库是AWS的RDS实例，我们没法在宿主机上安装pmm-client拿到Linux系统指标，但是pmm已提前集成cloudwatch plugin，可以通过AWS API在PMM的Grafana上展示Cloudwatch数据，这包含了一部分系统和MySQL指标。添加Cloudwatch到PMM展示需要提供对应账户的Access key，账户策略如下：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span> <span class="attr">&quot;Version&quot;</span><span class="punctuation">:</span> <span class="string">&quot;2012-10-17&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;Statement&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span><span class="punctuation">&#123;</span> <span class="attr">&quot;Sid&quot;</span><span class="punctuation">:</span> <span class="string">&quot;Stmt1508404837000&quot;</span><span class="punctuation">,</span></span><br><span class="line">                  <span class="attr">&quot;Effect&quot;</span><span class="punctuation">:</span> <span class="string">&quot;Allow&quot;</span><span class="punctuation">,</span></span><br><span class="line">                  <span class="attr">&quot;Action&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span> <span class="string">&quot;rds:DescribeDBInstances&quot;</span><span class="punctuation">,</span></span><br><span class="line">                              <span class="string">&quot;cloudwatch:GetMetricStatistics&quot;</span><span class="punctuation">,</span></span><br><span class="line">                              <span class="string">&quot;cloudwatch:ListMetrics&quot;</span><span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">                              <span class="attr">&quot;Resource&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span><span class="string">&quot;*&quot;</span><span class="punctuation">]</span> <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">                 <span class="punctuation">&#123;</span> <span class="attr">&quot;Sid&quot;</span><span class="punctuation">:</span> <span class="string">&quot;Stmt1508410723001&quot;</span><span class="punctuation">,</span></span><br><span class="line">                   <span class="attr">&quot;Effect&quot;</span><span class="punctuation">:</span> <span class="string">&quot;Allow&quot;</span><span class="punctuation">,</span></span><br><span class="line">                   <span class="attr">&quot;Action&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span> <span class="string">&quot;logs:DescribeLogStreams&quot;</span><span class="punctuation">,</span></span><br><span class="line">                               <span class="string">&quot;logs:GetLogEvents&quot;</span><span class="punctuation">,</span></span><br><span class="line">                               <span class="string">&quot;logs:FilterLogEvents&quot;</span> <span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">                               <span class="attr">&quot;Resource&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span> <span class="string">&quot;arn:aws:logs:*:*:log-group:RDSOSMetrics:*&quot;</span> <span class="punctuation">]</span><span class="punctuation">&#125;</span></span><br><span class="line">               <span class="punctuation">]</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure><h1 id="Pros-and-Cons"><a href="#Pros-and-Cons" class="headerlink" title="Pros and Cons"></a>Pros and Cons</h1><p>Percona自己的dashboard非常的丰富，配合Grafana高度灵活和炫酷的展示效果，基本覆盖了系统、数据库等等必须的、以及很多可能并不需要的指标了；加上学习成本低、开箱即用的特点，非常适用于快速构建全面的MySQL监控系统的场景。</p><p>不过另一方面，PMM的主要优势都体现在对Prometheus友好的封装上，QAN，Orchestrator这些功能目前还都非常鸡肋，实用性较低。同时也正是因为封装Prometheus，进行了大量预定义，导致Prometheus的部分功能在PMM上被限制甚至无法使用，一些二次改造的问题也在所难免。一旦需要深度定制监控系统，比如优化和扩容Prometheus、HA、自定义exporter等，用户最终将去学习Prometheus，也就没有使用PMM的必要了。</p><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><p><a href="https://www.percona.com/doc/percona-server/LATEST/installation/docker.html">https://www.percona.com/doc/percona-server/LATEST/installation/docker.html</a></p><p><a href="https://www.percona.com/doc/percona-monitoring-and-management/deploy/index.html">https://www.percona.com/doc/percona-monitoring-and-management/deploy/index.html</a></p><p><a href="https://www.percona.com/doc/percona-monitoring-and-management/pmm-admin.html">https://www.percona.com/doc/percona-monitoring-and-management/pmm-admin.html</a></p><p><a href="https://www.percona.com/doc/percona-monitoring-and-management/amazon-rds.html">https://www.percona.com/doc/percona-monitoring-and-management/amazon-rds.html</a></p><p><a href="https://docs.aws.amazon.com/IAM/latest/UserGuide/tutorial_cross-account-with-roles.html">https://docs.aws.amazon.com/IAM/latest/UserGuide/tutorial_cross-account-with-roles.html</a></p><p><a href="https://www.percona.com/doc/percona-monitoring-and-management/faq.html">https://www.percona.com/doc/percona-monitoring-and-management/faq.html</a></p>]]></content>
    
    
    <summary type="html">&lt;p&gt;PMM是Percona开源的监控系统(Percona Monitoring and Management)，主要用于监控MySQL、MongoDB等数据库的性能指标，目前最新版本是1.11.0。工作原因对其进行了一段时间的调研，本文将介绍如何在生产环境使用PMM快速构建MySQL数据库监控系统，包含基本原理、部署和优缺点比较等。&lt;/p&gt;
&lt;h1 id=&quot;Architecture&quot;&gt;&lt;a href=&quot;#Architecture&quot; class=&quot;headerlink&quot; title=&quot;Architecture&quot;&gt;&lt;/a&gt;Architecture&lt;/h1&gt;&lt;p&gt;关于PMM的架构，最主要是理解它是个基于Prometheus的系统，PMM的一些组件相当于对Prometheus中各个模块的封装，架构图如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://www.percona.com/doc/percona-monitoring-and-management/_images/diagram.pmm-architecture.png&quot; alt=&quot;PMM Architecture Overview&quot;&gt;&lt;/p&gt;
&lt;p&gt;结构分成了client-server部分：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Client：包含了各种exporter的daemon，以及用于管理他们的pmm-admin命令行工具&lt;/li&gt;
&lt;li&gt;Server - Metrics Monitor：本地存储的Prometheus、consul用于服务发现、Grafana出图；这块都是Prometheus技术栈&lt;/li&gt;
&lt;li&gt;Server - Query Analytics：Percona自研的查询分析组件，用于分析在DB端收集的慢查询，存储于MySQL中，最终以新的datasource注册至Grafana出图展示&lt;/li&gt;
&lt;li&gt;Server - &lt;a href=&quot;https://github.com/github/orchestrator&quot;&gt;Orchestrator&lt;/a&gt;：第三方工具orchestrator，图形化展示和管理MySQL实例的复制拓扑关系&lt;/li&gt;
&lt;/ul&gt;</summary>
    
    
    
    <category term="workspace" scheme="https://beanbee.github.io/categories/workspace/"/>
    
    
    <category term="MySQL" scheme="https://beanbee.github.io/tags/MySQL/"/>
    
    <category term="PMM" scheme="https://beanbee.github.io/tags/PMM/"/>
    
    <category term="Monitoring" scheme="https://beanbee.github.io/tags/Monitoring/"/>
    
    <category term="Percona" scheme="https://beanbee.github.io/tags/Percona/"/>
    
  </entry>
  
  <entry>
    <title>OSC工具如何处理外键约束</title>
    <link href="https://beanbee.github.io/blog/2018/how-osc-handle-table-with-fk/"/>
    <id>https://beanbee.github.io/blog/2018/how-osc-handle-table-with-fk/</id>
    <published>2018-06-06T08:16:22.000Z</published>
    <updated>2022-08-10T09:31:35.023Z</updated>
    
    <content type="html"><![CDATA[<p>首先不讨论MySQL 5.6+版本的Online DDL特性，因为它可以比较好的兼容外键表，这里说的是OSC工具操作外键表的场景，比如使用pt-online-schema-change&#x2F;gh-ost&#x2F;Facebook-OSC……</p><p>以上所有的工具都绕不开一个关键的cut-over环节，即用已经修改好表结构的“影子”表替换原表，完成新旧表结构变更。以A表的OSC为例，待切换表为B，这个阶段的操作就是：rename A to A_BAK, B to A。</p><p>那如果A是一个有外键关联的表会发生什么：</p><ol><li>A为外键的父表：rename操作之后所有A的子表的FK都指向了A_BAK表，而A_BAK表数据已经静止，因此需要把rebuild所有子表的FK（重新指向A），这个操作影响程度视子表数量递增。</li><li>A为外键的子表，创建B表时，MySQL在schema层级限制外键约束名称唯一，因此B的FK名称必须建个和A不一样的。这样切换后，A的FK定义相对旧A，名称不同，引用（REFERENCE）相同。</li></ol><p>可以看到第一种场景重建所有子表索引代价非常大，而且这个操作最好是在rename完成后尽快进行，否则如果这个时候子表的写入过来，极有可能会因为子表外键指向了A_BAK导致失败，影响业务（<code>pt-online-schema-change --alter-foreign-keys=rebuild_constraints</code>）。同时假设子表数量很多，或者外键约束关系很复杂，这种变更相当于”牵一发动全身“。</p><p>相比之下，第二种情况没有额外操作容易了不少，只是A的外键定义变了，影响逻辑<code>checksum</code>的结果。</p><p>看下OSC工具实际怎么支持这两种：</p><p><a href="https://www.percona.com/doc/percona-toolkit/3.0/pt-online-schema-change.html#cmdoption-pt-online-schema-change-alter-foreign-keys-method">pt-online-schema-change</a>：两种都支持，第一种会在rename后自动rebuild所有子表的FK，但是这期间也可能出现上述的写入失败问题，虽然概率相对小，不过仍有风险。第二种场景则是直接在rename后表的FK名称前面增加一个下划线前缀，以示区分，绕过MySQL的限制。</p><p><a href="https://github.com/github/gh-ost/blob/master/doc/requirements-and-limitations.md">gh-ost</a>则是两种场景都不支持，见到外键直接报错，当然你可以用它来给表去掉外键……</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;首先不讨论MySQL 5.6+版本的Online DDL特性，因为它可以比较好的兼容外键表，这里说的是OSC工具操作外键表的场景，比如使用pt-online-schema-change&amp;#x2F;gh-ost&amp;#x2F;Facebook-OSC……&lt;/p&gt;
&lt;p&gt;以上所有的</summary>
      
    
    
    
    <category term="workspace" scheme="https://beanbee.github.io/categories/workspace/"/>
    
    
    <category term="MySQL" scheme="https://beanbee.github.io/tags/MySQL/"/>
    
    <category term="OSC" scheme="https://beanbee.github.io/tags/OSC/"/>
    
    <category term="FK" scheme="https://beanbee.github.io/tags/FK/"/>
    
    <category term="DDL" scheme="https://beanbee.github.io/tags/DDL/"/>
    
  </entry>
  
  <entry>
    <title>记一个GTID复制bug</title>
    <link href="https://beanbee.github.io/blog/2018/bug-report-of-gtid-replicaiton-91086/"/>
    <id>https://beanbee.github.io/blog/2018/bug-report-of-gtid-replicaiton-91086/</id>
    <published>2018-05-31T02:00:22.000Z</published>
    <updated>2022-08-10T09:31:35.019Z</updated>
    
    <content type="html"><![CDATA[<p>MySQL基于GTID的复制强调主从库GTID的连续和一致，比如主库如果执行了1-4，那从库IO线程拿到1-4的变更后，不管有没有被SQL线程过滤，从库的GTID也得保留1-4。</p><p>这就会出现一个现象：假定从库使用MySQL的过滤规则不执行主库发送的一部分变更（配置<code>replication-wild-do-table=A.%</code>，GTID&#x3D;uuid:2被过滤），那MySQL这个时候会在从库用空事务的方式填充binlog，从而保证uuid:2在从库不丢失，主从“GTID”一致。也就是说主从数据可以不一致，但是GTID一致。印证了“从GTID连续一致指标判断主从一致”的依据是不正确的。</p><p>那MySQL不做这个填充，会发生什么？一个是从库出现很多”GTID空隙“，<code>Executed_Gtid_Set</code>变得特别长。再者，如果某个期间你期望通过<code>MASTER_AUTO_POSITION=1</code>切换新主库，新主库一看从库缺了这么多”空隙“，那从自己的binlog里面找到发给从库让它补上，结果就是从库依旧过滤这些变更不执行，依旧补不上”空隙“。更多的时候切换的新主库会因为binlog rotate原因，包含“空隙GTID”的binlog已不存在，<code>CHANGE MASTER</code>持续报1236错误，切换不成功，非常恼火。</p><p>既然DBA显式指定的跳过一部分表的变更，GTID也得保持主库连续。从以往的使用经验来看，MySQL确实也是这么做的，而这次碰到的bug则是这个地方MySQL实现的不完善引起的。</p><p>BUG简述：在使用过滤选项进行GTID主从复制时，主库的CREATE DATABASE, ALTER DATABASE &amp; DROP DATABASE变更如果在从库被过滤，该GTID将不会在从库<code>Executed_Gtid_Set</code>中保留。</p><span id="more"></span><p>复现方法：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br></pre></td><td class="code"><pre><span class="line">master - my.cnf:</span><br><span class="line">log-bin                                 = mysql-bin</span><br><span class="line">gtid-mode                               = ON</span><br><span class="line">log-slave-updates                       = ON</span><br><span class="line">enforce-gtid-consistency                = ON</span><br><span class="line">...</span><br><span class="line"></span><br><span class="line">slave - my.cnf:</span><br><span class="line">replicate-wild-do-table                 = mydb1.%</span><br><span class="line">gtid-mode                               = ON</span><br><span class="line">log-slave-updates                       = ON</span><br><span class="line">enforce-gtid-consistency                = ON</span><br><span class="line">...</span><br><span class="line"></span><br><span class="line">master status information:</span><br><span class="line">mysql&gt; show master status ;</span><br><span class="line">+------------------+----------+--------------+------------------+--------------------------------------------+</span><br><span class="line">| File             | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set                          |</span><br><span class="line">+------------------+----------+--------------+------------------+--------------------------------------------+</span><br><span class="line">| mysql-bin.000002 |      627 |              |                  | 356d0651-5e4c-11e8-846c-126bb17ce918:1-345 |</span><br><span class="line">+------------------+----------+--------------+------------------+--------------------------------------------+</span><br><span class="line">1 row <span class="keyword">in</span> <span class="built_in">set</span> (0.01 sec)</span><br><span class="line"></span><br><span class="line">replication status of slave:</span><br><span class="line">mysql&gt; show slave status \G</span><br><span class="line">*************************** 1. row ***************************</span><br><span class="line">               Slave_IO_State: Waiting <span class="keyword">for</span> master to send event</span><br><span class="line">                  Master_Host: 10.23.7.81</span><br><span class="line">                  Master_User: slave</span><br><span class="line">                  Master_Port: 3306</span><br><span class="line">                Connect_Retry: 60</span><br><span class="line">              Master_Log_File: mysql-bin.000002</span><br><span class="line">          Read_Master_Log_Pos: 627</span><br><span class="line">               Relay_Log_File: freewheel-relay-bin.000002</span><br><span class="line">                Relay_Log_Pos: 554</span><br><span class="line">        Relay_Master_Log_File: mysql-bin.000002</span><br><span class="line">             Slave_IO_Running: Yes</span><br><span class="line">            Slave_SQL_Running: Yes</span><br><span class="line">              Replicate_Do_DB:</span><br><span class="line">          Replicate_Ignore_DB:</span><br><span class="line">           Replicate_Do_Table:</span><br><span class="line">       Replicate_Ignore_Table:</span><br><span class="line">      Replicate_Wild_Do_Table: mydb1.%</span><br><span class="line">  Replicate_Wild_Ignore_Table:</span><br><span class="line">                   Last_Errno: 0</span><br><span class="line">                   Last_Error:</span><br><span class="line">                 Skip_Counter: 0</span><br><span class="line">          Exec_Master_Log_Pos: 627</span><br><span class="line">              Relay_Log_Space: 762</span><br><span class="line">              Until_Condition: None</span><br><span class="line">               Until_Log_File:</span><br><span class="line">                Until_Log_Pos: 0</span><br><span class="line">           Master_SSL_Allowed: No</span><br><span class="line">           Master_SSL_CA_File:</span><br><span class="line">           Master_SSL_CA_Path:</span><br><span class="line">              Master_SSL_Cert:</span><br><span class="line">            Master_SSL_Cipher:</span><br><span class="line">               Master_SSL_Key:</span><br><span class="line">        Seconds_Behind_Master: 0</span><br><span class="line">Master_SSL_Verify_Server_Cert: No</span><br><span class="line">                Last_IO_Errno: 0</span><br><span class="line">                Last_IO_Error:</span><br><span class="line">               Last_SQL_Errno: 0</span><br><span class="line">               Last_SQL_Error:</span><br><span class="line">  Replicate_Ignore_Server_Ids:</span><br><span class="line">             Master_Server_Id: 27087</span><br><span class="line">                  Master_UUID: 356d0651-5e4c-11e8-846c-126bb17ce918</span><br><span class="line">             Master_Info_File: /home/mysql/data/master.info</span><br><span class="line">                    SQL_Delay: 0</span><br><span class="line">          SQL_Remaining_Delay: NULL</span><br><span class="line">      Slave_SQL_Running_State: Slave has <span class="built_in">read</span> all relay <span class="built_in">log</span>; waiting <span class="keyword">for</span> the slave I/O thread to update it</span><br><span class="line">           Master_Retry_Count: 86400</span><br><span class="line">                  Master_Bind:</span><br><span class="line">      Last_IO_Error_Timestamp:</span><br><span class="line">     Last_SQL_Error_Timestamp:</span><br><span class="line">               Master_SSL_Crl:</span><br><span class="line">           Master_SSL_Crlpath:</span><br><span class="line">           Retrieved_Gtid_Set: 356d0651-5e4c-11e8-846c-126bb17ce918:345</span><br><span class="line">            Executed_Gtid_Set: 356d0651-5e4c-11e8-846c-126bb17ce918:1-345</span><br><span class="line">                Auto_Position: 1</span><br><span class="line">1 row <span class="keyword">in</span> <span class="built_in">set</span> (0.00 sec)</span><br><span class="line"></span><br><span class="line">Here<span class="string">&#x27;re steps to verify:</span></span><br><span class="line"><span class="string">1. Send INSERT on mydb1.t on master</span></span><br><span class="line"><span class="string">master - GTID+1:</span></span><br><span class="line"><span class="string">mysql&gt; insert into mydb1.t values (1);</span></span><br><span class="line"><span class="string">Query OK, 1 row affected (0.00 sec)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">mysql&gt; show master status ;</span></span><br><span class="line"><span class="string">+------------------+----------+--------------+------------------+--------------------------------------------+</span></span><br><span class="line"><span class="string">| File             | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set                          |</span></span><br><span class="line"><span class="string">+------------------+----------+--------------+------------------+--------------------------------------------+</span></span><br><span class="line"><span class="string">| mysql-bin.000002 |      859 |              |                  | 356d0651-5e4c-11e8-846c-126bb17ce918:1-346 |</span></span><br><span class="line"><span class="string">+------------------+----------+--------------+------------------+--------------------------------------------+</span></span><br><span class="line"><span class="string">1 row in set (0.00 sec)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">slave - GTID+1:</span></span><br><span class="line"><span class="string">mysql&gt; show slave status \G</span></span><br><span class="line"><span class="string">...</span></span><br><span class="line"><span class="string">      Replicate_Wild_Do_Table: mydb1.%</span></span><br><span class="line"><span class="string">           Retrieved_Gtid_Set: 356d0651-5e4c-11e8-846c-126bb17ce918:345-346</span></span><br><span class="line"><span class="string">            Executed_Gtid_Set: 356d0651-5e4c-11e8-846c-126bb17ce918:1-346</span></span><br><span class="line"><span class="string">...</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">2. Send INSERT on mydb2.t on master</span></span><br><span class="line"><span class="string">master - GTID+1:</span></span><br><span class="line"><span class="string">mysql&gt; insert into mydb2.t values (1);</span></span><br><span class="line"><span class="string">Query OK, 1 row affected (0.00 sec)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">mysql&gt; show master status ;</span></span><br><span class="line"><span class="string">+------------------+----------+--------------+------------------+--------------------------------------------+</span></span><br><span class="line"><span class="string">| File             | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set                          |</span></span><br><span class="line"><span class="string">+------------------+----------+--------------+------------------+--------------------------------------------+</span></span><br><span class="line"><span class="string">| mysql-bin.000002 |     1091 |              |                  | 356d0651-5e4c-11e8-846c-126bb17ce918:1-347 |</span></span><br><span class="line"><span class="string">+------------------+----------+--------------+------------------+--------------------------------------------+</span></span><br><span class="line"><span class="string">1 row in set (0.00 sec)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">mysql&gt; select * from mydb2.t;</span></span><br><span class="line"><span class="string">+------+</span></span><br><span class="line"><span class="string">| x    |</span></span><br><span class="line"><span class="string">+------+</span></span><br><span class="line"><span class="string">|    1 |</span></span><br><span class="line"><span class="string">+------+</span></span><br><span class="line"><span class="string">1 row in set (0.00 sec)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">slave - GTID+1:</span></span><br><span class="line"><span class="string">mysql&gt; select * from mydb2.t;</span></span><br><span class="line"><span class="string">Empty set (0.00 sec)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">mysql&gt; show slave status \G</span></span><br><span class="line"><span class="string">...</span></span><br><span class="line"><span class="string">      Replicate_Wild_Do_Table: mydb1.%</span></span><br><span class="line"><span class="string">           Retrieved_Gtid_Set: 356d0651-5e4c-11e8-846c-126bb17ce918:345-347</span></span><br><span class="line"><span class="string">            Executed_Gtid_Set: 356d0651-5e4c-11e8-846c-126bb17ce918:1-347</span></span><br><span class="line"><span class="string">...</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">3. Send CREATE DATABASE xxx on master</span></span><br><span class="line"><span class="string">master - GTID+1:</span></span><br><span class="line"><span class="string">mysql&gt; create database mydb3;</span></span><br><span class="line"><span class="string">Query OK, 1 row affected (0.00 sec)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">mysql&gt; show master status ;</span></span><br><span class="line"><span class="string">+------------------+----------+--------------+------------------+--------------------------------------------+</span></span><br><span class="line"><span class="string">| File             | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set                          |</span></span><br><span class="line"><span class="string">+------------------+----------+--------------+------------------+--------------------------------------------+</span></span><br><span class="line"><span class="string">| mysql-bin.000002 |     1236 |              |                  | 356d0651-5e4c-11e8-846c-126bb17ce918:1-348 |</span></span><br><span class="line"><span class="string">+------------------+----------+--------------+------------------+--------------------------------------------+</span></span><br><span class="line"><span class="string">1 row in set (0.00 sec)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">slave - GTID retrieved but not changed on Executed_Gtid_Set:  =&gt; 丢失一个GTID</span></span><br><span class="line"><span class="string">mysql&gt; show slave status \G</span></span><br><span class="line"><span class="string">...</span></span><br><span class="line"><span class="string">      Replicate_Wild_Do_Table: mydb1.%</span></span><br><span class="line"><span class="string">           Retrieved_Gtid_Set: 356d0651-5e4c-11e8-846c-126bb17ce918:345-348</span></span><br><span class="line"><span class="string">            Executed_Gtid_Set: 356d0651-5e4c-11e8-846c-126bb17ce918:1-347</span></span><br><span class="line"><span class="string">...</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">4. Send INSERT on mydb1.t on master</span></span><br><span class="line"><span class="string">master - GTID+1:</span></span><br><span class="line"><span class="string">mysql&gt; insert into mydb1.t values (1);</span></span><br><span class="line"><span class="string">Query OK, 1 row affected (0.00 sec)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">mysql&gt; show master status ;</span></span><br><span class="line"><span class="string">+------------------+----------+--------------+------------------+--------------------------------------------+</span></span><br><span class="line"><span class="string">| File             | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set                          |</span></span><br><span class="line"><span class="string">+------------------+----------+--------------+------------------+--------------------------------------------+</span></span><br><span class="line"><span class="string">| mysql-bin.000002 |     1468 |              |                  | 356d0651-5e4c-11e8-846c-126bb17ce918:1-349 |</span></span><br><span class="line"><span class="string">+------------------+----------+--------------+------------------+--------------------------------------------+</span></span><br><span class="line"><span class="string">1 row in set (0.00 sec)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">slave - broken GTID set on Executed_Gtid_Set:             =&gt; 出现GTID空隙</span></span><br><span class="line"><span class="string">...</span></span><br><span class="line"><span class="string">      Replicate_Wild_Do_Table: mydb1.%</span></span><br><span class="line"><span class="string">           Retrieved_Gtid_Set: 356d0651-5e4c-11e8-846c-126bb17ce918:345-349</span></span><br><span class="line"><span class="string">            Executed_Gtid_Set: 356d0651-5e4c-11e8-846c-126bb17ce918:1-347:349</span></span><br><span class="line"><span class="string">...</span></span><br></pre></td></tr></table></figure><p>反馈bug后得到<a href="https://bugs.mysql.com/bug.php?id=91086">官方回复</a>，已经在新版本<em>8.0.12, 5.7.23, 5.6.41</em>中修复，虽然都还没有release：</p><blockquote><p>Thanks for the report. Changelog entry added for MySQL 8.0.12, 5.7.23, and 5.6.41:</p><p>When GTIDs are in use for replication, replicated transactions that are filtered out on the slave are persisted. If binary logging is enabled on the slave, the filtered-out transaction is written to the binary log as a Gtid_log_event followed by an empty transaction containing only BEGIN and COMMIT statements. If binary logging is disabled, the GTID of the filtered-out transaction is written to the mysql.gtid_executed table. This process ensures that there are no gaps in the set of executed GTIDs, and that the filtered-out transactions are not retrieved again if the slave reconnects to the master. Previously, this process was not done for CREATE DATABASE, ALTER DATABASE, and DROP DATABASE statements, but it is now carried out for those statements as well as for others.</p></blockquote><p>总结的话，现阶段如果用了过滤选项<code>replicate-*-table</code>进行复制，避免在主库进行CREATE&#x2F;DROP&#x2F;ALTER DATABASE操作，否则会引起该GTID在从库<code>Executed_Gtid_Set</code>中缺失。当然建议还是少用<code>replicate-*-table</code></p>]]></content>
    
    
    <summary type="html">&lt;p&gt;MySQL基于GTID的复制强调主从库GTID的连续和一致，比如主库如果执行了1-4，那从库IO线程拿到1-4的变更后，不管有没有被SQL线程过滤，从库的GTID也得保留1-4。&lt;/p&gt;
&lt;p&gt;这就会出现一个现象：假定从库使用MySQL的过滤规则不执行主库发送的一部分变更（配置&lt;code&gt;replication-wild-do-table=A.%&lt;/code&gt;，GTID&amp;#x3D;uuid:2被过滤），那MySQL这个时候会在从库用空事务的方式填充binlog，从而保证uuid:2在从库不丢失，主从“GTID”一致。也就是说主从数据可以不一致，但是GTID一致。印证了“从GTID连续一致指标判断主从一致”的依据是不正确的。&lt;/p&gt;
&lt;p&gt;那MySQL不做这个填充，会发生什么？一个是从库出现很多”GTID空隙“，&lt;code&gt;Executed_Gtid_Set&lt;/code&gt;变得特别长。再者，如果某个期间你期望通过&lt;code&gt;MASTER_AUTO_POSITION=1&lt;/code&gt;切换新主库，新主库一看从库缺了这么多”空隙“，那从自己的binlog里面找到发给从库让它补上，结果就是从库依旧过滤这些变更不执行，依旧补不上”空隙“。更多的时候切换的新主库会因为binlog rotate原因，包含“空隙GTID”的binlog已不存在，&lt;code&gt;CHANGE MASTER&lt;/code&gt;持续报1236错误，切换不成功，非常恼火。&lt;/p&gt;
&lt;p&gt;既然DBA显式指定的跳过一部分表的变更，GTID也得保持主库连续。从以往的使用经验来看，MySQL确实也是这么做的，而这次碰到的bug则是这个地方MySQL实现的不完善引起的。&lt;/p&gt;
&lt;p&gt;BUG简述：在使用过滤选项进行GTID主从复制时，主库的CREATE DATABASE, ALTER DATABASE &amp;amp; DROP DATABASE变更如果在从库被过滤，该GTID将不会在从库&lt;code&gt;Executed_Gtid_Set&lt;/code&gt;中保留。&lt;/p&gt;</summary>
    
    
    
    <category term="workspace" scheme="https://beanbee.github.io/categories/workspace/"/>
    
    
    <category term="MySQL" scheme="https://beanbee.github.io/tags/MySQL/"/>
    
    <category term="GTID" scheme="https://beanbee.github.io/tags/GTID/"/>
    
    <category term="Replication" scheme="https://beanbee.github.io/tags/Replication/"/>
    
    <category term="Bug" scheme="https://beanbee.github.io/tags/Bug/"/>
    
  </entry>
  
  <entry>
    <title>判断GTID切换是否会出现Error:1236问题</title>
    <link href="https://beanbee.github.io/blog/2018/avoid-err-master-purged-gtids-required/"/>
    <id>https://beanbee.github.io/blog/2018/avoid-err-master-purged-gtids-required/</id>
    <published>2018-05-17T07:00:22.000Z</published>
    <updated>2022-08-10T09:31:35.019Z</updated>
    
    <content type="html"><![CDATA[<p>先从线上的一个CASE说起，在使用GTID的AUTO_POSITION&#x3D;1模式切换主库时，遭遇<a href="https://dev.mysql.com/doc/refman/5.6/en/error-messages-server.html#error_er_master_fatal_error_reading_binlog">Error: 1236</a>错误：</p><blockquote><p>2018-05-08 14:45:52 26147 [ERROR] Slave I&#x2F;O: Got fatal error 1236 from master when reading data from binary log: ‘The slave is connecting using CHANGE MASTER TO MASTER_AUTO_POSITION &#x3D; 1, but the master has purged binary logs containing GTIDs that the slave requires.’, Error_code: 1236</p></blockquote><p>错误日志的说明是：从库需要一部分GTID集合来补齐数据，而缺失的部分恰好被主库purged了，所以没法建立复制关系。但是缺失的GTID集合是哪些，怎么计算出来的没说。</p><p>从MySQL代码里面找下线索，先从官方文档里得知Error:1236对应错误<code>ER_MASTER_FATAL_ERROR_READING_BINLOG</code>，然后定位到<code>sql/rpl_master.cc</code>文件1007行，MySQL版本：5.6.39：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">  Setting GTID_PURGED (when GTID_EXECUTED set is empty i.e., when</span></span><br><span class="line"><span class="comment">  previous_gtids are also empty) will make binlog rotate. That</span></span><br><span class="line"><span class="comment">  leaves first binary log with empty previous_gtids and second</span></span><br><span class="line"><span class="comment">  binary log&#x27;s previous_gtids with the value of gtid_purged.</span></span><br><span class="line"><span class="comment">  In find_first_log_not_in_gtid_set() while we search for a binary</span></span><br><span class="line"><span class="comment">  log whose previous_gtid_set is subset of slave_gtid_executed,</span></span><br><span class="line"><span class="comment">  in this particular case, server will always find the first binary</span></span><br><span class="line"><span class="comment">  log with empty previous_gtids which is subset of any given</span></span><br><span class="line"><span class="comment">  slave_gtid_executed. Thus Master thinks that it found the first</span></span><br><span class="line"><span class="comment">  binary log which is actually not correct and unable to catch</span></span><br><span class="line"><span class="comment">  this error situation. Hence adding below extra if condition</span></span><br><span class="line"><span class="comment">  to check the situation. Slave should know about Master&#x27;s purged GTIDs.</span></span><br><span class="line"><span class="comment">  If Slave&#x27;s GTID executed + retrieved set does not contain Master&#x27;s</span></span><br><span class="line"><span class="comment">  complete purged GTID list, that means Slave is requesting(expecting)</span></span><br><span class="line"><span class="comment">  GTIDs which were purged by Master. We should let Slave know about the</span></span><br><span class="line"><span class="comment">  situation. i.e., throw error if slave&#x27;s GTID executed set is not</span></span><br><span class="line"><span class="comment">  a superset of Master&#x27;s purged GTID set.</span></span><br><span class="line"><span class="comment">  The other case, where user deleted binary logs manually</span></span><br><span class="line"><span class="comment">  (without using &#x27;PURGE BINARY LOGS&#x27; command) but gtid_purged</span></span><br><span class="line"><span class="comment">  is not set by the user, the following if condition cannot catch it.</span></span><br><span class="line"><span class="comment">  But that is not a problem because in find_first_log_not_in_gtid_set()</span></span><br><span class="line"><span class="comment">  while checking for subset previous_gtids binary log, the logic</span></span><br><span class="line"><span class="comment">  will not find one and an error ER_MASTER_HAS_PURGED_REQUIRED_GTIDS</span></span><br><span class="line"><span class="comment">  is thrown from there.</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="keyword">if</span> (!gtid_state-&gt;get_lost_gtids()-&gt;is_subset(slave_gtid_executed))</span><br><span class="line">&#123;</span><br><span class="line">  errmsg= ER(ER_MASTER_HAS_PURGED_REQUIRED_GTIDS);</span><br><span class="line">  my_errno= ER_MASTER_FATAL_ERROR_READING_BINLOG;</span><br><span class="line">  global_sid_lock-&gt;unlock();</span><br><span class="line">  GOTO_ERR;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>从代码和注释内容可以了解到，从库executed+retrieved的gtid集合如果不完全包含主库purged的gtid集合，则说明从库无法从主库binlog中拿到想要的gtid集合。转换下即是主库与从库executed gtid的差集，如果已经在<code>gtid_purged</code>集合中，即无法建立同步，发生1236错误。</p><p>因此，可以在主库通过下面方法提前判断切换到新主库时是否会出现1236错误：</p><ol><li>去从库停止同步后的gtid_executed集合，记为slave.gtid_executed</li><li>新主库计算gtid_subtract(@@global.gtid_executed, slave.gtid_executed)结果</li><li>对于2步结果，每个uuid的gtid集合，计算gtid_subset(set, @@global.gtid_purged)，为1即出错</li></ol><p>伪代码如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> <span class="built_in">set</span> <span class="keyword">in</span> `gtid_subtract(@@master.gtid_executed, @@slave.gtid_executed)`; <span class="keyword">do</span></span><br><span class="line">    <span class="keyword">if</span> gtid_subset(<span class="built_in">set</span>, @@master.gtid_purged); &#123;</span><br><span class="line">    <span class="built_in">return</span> ER_MASTER_HAS_PURGED_REQUIRED_GTIDS</span><br><span class="line">    &#125;</span><br><span class="line"><span class="keyword">done</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">return</span> 0</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;先从线上的一个CASE说起，在使用GTID的AUTO_POSITION&amp;#x3D;1模式切换主库时，遭遇&lt;a href=&quot;https://dev.mysql.com/doc/refman/5.6/en/error-messages-server.html#error_er_</summary>
      
    
    
    
    <category term="workspace" scheme="https://beanbee.github.io/categories/workspace/"/>
    
    
    <category term="MySQL" scheme="https://beanbee.github.io/tags/MySQL/"/>
    
    <category term="GTID" scheme="https://beanbee.github.io/tags/GTID/"/>
    
    <category term="Troubleshooting" scheme="https://beanbee.github.io/tags/Troubleshooting/"/>
    
  </entry>
  
  <entry>
    <title>gh-ost无损cut-over方案</title>
    <link href="https://beanbee.github.io/blog/2018/ghost-cut-over-steps/"/>
    <id>https://beanbee.github.io/blog/2018/ghost-cut-over-steps/</id>
    <published>2018-05-05T02:49:53.000Z</published>
    <updated>2022-08-10T09:31:35.023Z</updated>
    
    <content type="html"><![CDATA[<p>gh-ost作为Github开源的在线表结构修改工具，工作原理上和社区已有的OSC工具基本相似，概括来说：</p><ol><li>主库创建和旧表相同schema的空表，alter table table_new…</li><li>导入源表数据，追加增量（gh-ost使用的binlog回放）</li><li>等待“恰当”的时机，rename table完成新旧表的互换（cut-over）</li></ol><p><img src="https://raw.githubusercontent.com/github/gh-ost/master/doc/images/gh-ost-general-flow.png" alt="gh-ost overview"></p><p>除了提供了一系列DBA友好的配置&#x2F;操作方法外，gh-ost另一个亮点在于和Facebook OSC相比，它提供了默认无损的cut-over方案，后者则可能在这期间出现一定的请求失败（table not found）</p><span id="more"></span><h1 id="Cut-over-Overview"><a href="#Cut-over-Overview" class="headerlink" title="Cut-over Overview"></a>Cut-over Overview</h1><p>在线表结构修改的工具都需要在新schema的表生效提供服务前，同时在DB中存在新旧两张不同schema的表，这期间旧表A的变更会持续的通过trigger（Facebook OSC&#x2F;Percona OSC）或者binlog回放（gh-ost）方式合入待切换表B。</p><p>Cut-over发生时，首先需要杜绝对A表的持续写入，即保证A数据静止，一般需要lock tables，紧接着在检测B与A数据&#x2F;数据行一致的时候，进行表名更改，完成A&#x3D;&gt;X, B&#x3D;&gt;A的互换。关键点在于怎么保证切换前一刻新旧表数据追平，使得被阻塞的请求能够在切换后下发至新表。</p><p>OK，会有人提到，在<code>lock tables</code>这个session之后做<code>rename table</code>不行吗？这里先说明MySQL做rename的两种方式：</p><ul><li><code>RENAME TABLE</code> - 能够完成多表rename，保证多表rename操作原子。然而<code>RENAME TABLE</code>无法在lock tables的session中进行，这就成了影响cut-over阶段最大的<strong>MySQL限制</strong>。</li><li><code>ALTER TABLE RENAME</code> - 能够在lock tables过程中使用，本身会触发隐式提交，最重要的是无法单次rename多张表，这使得A&#x3D;&gt;X, B&#x3D;&gt;A这个过程无法原子化。</li></ul><p>第一种方式即无法满足lock同时rename。而Facebook的OSC方案使用第二种方法，将A&#x3D;&gt;X, B&#x3D;&gt;A过程拆分成一个session中两条<code>ALTER TABLE RENAME</code>语句。结果就是，在两次<code>ALTER TABLE RENAME</code>之间访问A表的请求出现<code>table not found</code>报错，应用请求失败。</p><h1 id="Cut-over-in-Gh-ost"><a href="#Cut-over-in-Gh-ost" class="headerlink" title="Cut-over in Gh-ost"></a>Cut-over in Gh-ost</h1><p>下面来看gh-ost工具如何完成异步、原子的cut-over：</p><blockquote><p>gh-ost完成cut-over只需要两个DB链接，下面以C10, C20标识，正常的写入请求标识为C1..C9, C11..C19, C21..C29。tbl为旧表，ghost表为已经schema changed的新表。</p><ol><li>C1..C9：对 <code>tbl</code> 进行正常的DML操作，包含 <code>INSERT, UPDATE, DELETE</code></li><li>C10：<code>CREATE TABLE tbl_old (id int primary key) COMMENT=&#39;magic-be-here&#39;</code></li><li>C10：<code>LOCK TABLES tbl WRITE, tbl_old WRITE</code></li><li>C11..C19：新请求，对 <code>tbl</code> 的DML操作被<code>LOCK</code>阻塞</li><li>C20: <code>RENAME TABLE tbl TO tbl_old, ghost TO tbl</code> - 该语句依旧被<code>LOCK</code>阻塞，但是在阻塞的队列中，优先级高于C11..C19, C1..C9，以及任何尝试对<code>tbl</code>DML的操作</li><li>C21..C29：新请求，期望操作<code>tbl</code>，但依旧被<code>LOCK</code>, <code>RENAME</code>阻塞</li><li>C10：通过show processlist检测到C20的<code>RENAME</code>操作已经发起（处于blocked状态）</li><li>C10：<code>DROP TABLE tbl_old</code> - <code>tbl</code>依旧被locked，所有链接仍然处于阻塞状态</li><li>C10：<code>UNLOCK TABLES</code> - <code>RENAME</code>第一个被执行，<code>ghost</code>表被提为<code>tbl</code>，紧接着C1..C9, C11..C19, C21..C29的请求直接发至”新“表<code>tbl</code></li></ol><p><u><em>译自：<a href="https://github.com/github/gh-ost/issues/82">https://github.com/github/gh-ost/issues/82</a></em></u></p></blockquote><p>几个关键点：</p><ul><li>允许持有<code>WRITE LOCK</code>的session进行<code>DROP TABLE</code></li><li>在处于blocked状态下，<code>RENAME</code>操作始终优先级大于 <code>INSERT/UPDATE/DELETE</code>操作，不区分先后（<a href="https://github.com/mysql/mysql-server/blob/a533e2c786164af9bd276660b972d93649434297/sql/mdl.cc#L2312">lock acquirement algorithm</a>）</li><li><code>tbl_old</code>起到了占位作用，如果C10在C20的RENAME操作之前或之后意外中断，C20都会因为<code>tbl_old</code>表已经存在而报错中止，从而不会在write lock消失的情况下（C10中断）意外RENAME以至出现可能的不一致。</li></ul><p>以上步骤C10、C20在任一阶段出现问题，均不会导致意外<code>RENAME</code>。正常情况下，应用请求会在block很短一段时间后继续下发至”新表“，无流损感知。这个切换开始时间以及block时间也可由gh-ost来控制。</p><h1 id="Practical-Example"><a href="#Practical-Example" class="headerlink" title="Practical Example"></a>Practical Example</h1><p>下面为通过gh-ost工具修改一个表的engine：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">$ ./gh-ost \</span><br><span class="line">--max-load=Threads_running=25 \</span><br><span class="line">--critical-load=Threads_running=1000 \</span><br><span class="line">--chunk-size=1000 \</span><br><span class="line">--throttle-control-replicas=<span class="string">&quot;127.0.0.1&quot;</span> \</span><br><span class="line">--max-lag-millis=1500 \</span><br><span class="line">--user=<span class="string">&quot;osc&quot;</span> \</span><br><span class="line">--password=<span class="string">&#x27;xxx&#x27;</span> \</span><br><span class="line">--host=127.0.0.1 \</span><br><span class="line">--port=3306 \</span><br><span class="line">--allow-on-master \</span><br><span class="line">--database=<span class="string">&quot;osctest&quot;</span> \</span><br><span class="line">--table=<span class="string">&quot;gh_ost_test&quot;</span> \</span><br><span class="line">--verbose \</span><br><span class="line">--alter=<span class="string">&quot;engine=innodb&quot;</span> \</span><br><span class="line">--switch-to-rbr \</span><br><span class="line">--allow-master-master \</span><br><span class="line">--cut-over=default \</span><br><span class="line">--exact-rowcount \</span><br><span class="line">--concurrent-rowcount \</span><br><span class="line">--timestamp-old-table \</span><br><span class="line">--default-retries=120 \</span><br><span class="line">--panic-flag-file=./ghost.panic.flag \</span><br><span class="line">--postpone-cut-over-flag-file=./ghost.postpone.flag \</span><br><span class="line">--skip-foreign-key-checks \</span><br><span class="line">--execute</span><br></pre></td></tr></table></figure><p>从主库的查询日志可以对应的看到C10、C20的操作，C10对应39，C20对应45。</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">39</span> Query<span class="keyword">START</span> TRANSACTION</span><br><span class="line"><span class="number">39</span> Query<span class="keyword">select</span> connection_id()</span><br><span class="line"><span class="number">39</span> Query<span class="keyword">select</span> get_lock(<span class="string">&#x27;gh-ost.39.lock&#x27;</span>, <span class="number">0</span>)</span><br><span class="line"><span class="number">39</span> Query<span class="keyword">set</span> session lock_wait_timeout:<span class="operator">=</span><span class="number">6</span></span><br><span class="line"><span class="number">45</span> Query<span class="keyword">show</span> <span class="comment">/* gh-ost */</span> <span class="keyword">table</span> status <span class="keyword">from</span> `osctest` <span class="keyword">like</span> <span class="string">&#x27;_gh_ost_test_20180505153113_del&#x27;</span></span><br><span class="line"><span class="number">45</span> Query<span class="keyword">create</span> <span class="comment">/* gh-ost */</span> <span class="keyword">table</span> `osctest`.`_gh_ost_test_20180505153113_del` (</span><br><span class="line"><span class="number">39</span> Querylock <span class="comment">/* gh-ost */</span> tables `osctest`.`gh_ost_test` write, `osctest`.`_gh_ost_test_20180505153113_del` write</span><br><span class="line"><span class="number">45</span> Query<span class="keyword">START</span> TRANSACTION</span><br><span class="line"><span class="number">45</span> Query<span class="keyword">select</span> connection_id()</span><br><span class="line"><span class="number">45</span> Query<span class="keyword">set</span> session lock_wait_timeout:<span class="operator">=</span><span class="number">3</span></span><br><span class="line"><span class="number">45</span> Queryrename <span class="comment">/* gh-ost */</span> <span class="keyword">table</span> `osctest`.`gh_ost_test` <span class="keyword">to</span> `osctest`.`_gh_ost_test_20180505153113_del`, `osctest`.`_gh_ost_test_gho` <span class="keyword">to</span> `osctest`.`gh_ost_test`</span><br><span class="line"><span class="number">39</span> Query<span class="keyword">drop</span> <span class="comment">/* gh-ost */</span> <span class="keyword">table</span> if <span class="keyword">exists</span> `osctest`.`_gh_ost_test_20180505153113_del`</span><br><span class="line"><span class="number">39</span> Queryunlock tables</span><br><span class="line"><span class="number">39</span> <span class="keyword">Close</span> stmt</span><br><span class="line"><span class="number">45</span> <span class="keyword">Close</span> stmt</span><br><span class="line"><span class="number">39</span> Query<span class="keyword">drop</span> <span class="comment">/* gh-ost */</span> <span class="keyword">table</span> if <span class="keyword">exists</span> `osctest`.`_gh_ost_test_ghc`</span><br><span class="line"><span class="number">45</span> Quit</span><br><span class="line"><span class="number">39</span> Quit</span><br></pre></td></tr></table></figure><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><p><a href="https://github.com/github/gh-ost">https://github.com/github/gh-ost</a></p><p><a href="https://github.com/github/gh-ost/issues/82">https://github.com/github/gh-ost/issues/82</a></p><p><a href="https://github.com/github/gh-ost/blob/master/doc/cut-over.md">https://github.com/github/gh-ost/blob/master/doc/cut-over.md</a></p><p><a href="https://dev.mysql.com/doc/refman/5.7/en/lock-tables.html">https://dev.mysql.com/doc/refman/5.7/en/lock-tables.html</a></p><p><a href="https://www.facebook.com/notes/mysql-at-facebook/online-schema-change-for-mysql/430801045932/">Facebook Online Schema Change for MySQL</a></p>]]></content>
    
    
    <summary type="html">&lt;p&gt;gh-ost作为Github开源的在线表结构修改工具，工作原理上和社区已有的OSC工具基本相似，概括来说：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;主库创建和旧表相同schema的空表，alter table table_new…&lt;/li&gt;
&lt;li&gt;导入源表数据，追加增量（gh-ost使用的binlog回放）&lt;/li&gt;
&lt;li&gt;等待“恰当”的时机，rename table完成新旧表的互换（cut-over）&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/github/gh-ost/master/doc/images/gh-ost-general-flow.png&quot; alt=&quot;gh-ost overview&quot;&gt;&lt;/p&gt;
&lt;p&gt;除了提供了一系列DBA友好的配置&amp;#x2F;操作方法外，gh-ost另一个亮点在于和Facebook OSC相比，它提供了默认无损的cut-over方案，后者则可能在这期间出现一定的请求失败（table not found）&lt;/p&gt;</summary>
    
    
    
    <category term="workspace" scheme="https://beanbee.github.io/categories/workspace/"/>
    
    
    <category term="MySQL" scheme="https://beanbee.github.io/tags/MySQL/"/>
    
    <category term="OSC" scheme="https://beanbee.github.io/tags/OSC/"/>
    
    <category term="gh-ost" scheme="https://beanbee.github.io/tags/gh-ost/"/>
    
  </entry>
  
  <entry>
    <title>Quick Manual of mysqlbinlog</title>
    <link href="https://beanbee.github.io/blog/2018/quick-maunal-myqlbinlog/"/>
    <id>https://beanbee.github.io/blog/2018/quick-maunal-myqlbinlog/</id>
    <published>2018-04-14T08:04:26.000Z</published>
    <updated>2022-08-10T09:31:35.023Z</updated>
    
    <content type="html"><![CDATA[<p>In case of Database Recovery after unexpected data corruption, list some commonly used scenarios of <em>mysqlbinlog</em> for processing binary log files.</p><h1 id="Display-Row-Events"><a href="#Display-Row-Events" class="headerlink" title="Display Row Events"></a>Display Row Events</h1><p>Convert binary events to SQL statements, DDL output will be displayed as a raw statement, DML output will be presented as lines beginning with <code>###</code>, those are “pseudo-SQL” statements which are not executable.</p><p>For DML pseudo-SQL statements, they do not correspond exactly to the original SQL statements that generated the events, The original column names are lost and replaced by <code>@*N*</code>, where <em>N</em> is a column number. </p><p>Also if you are using multi-character set data, those character set information is not available in the display.</p><span id="more"></span><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line">$ mysqlbinlog --base64-output=decode-rows -v mysql-bin.000008</span><br><span class="line">...</span><br><span class="line"><span class="comment"># at 347</span></span><br><span class="line"><span class="comment">#180412  9:52:43 server id 231144  end_log_pos 395 CRC32 0x84460ead     GTID [commit=yes]</span></span><br><span class="line">SET @@SESSION.GTID_NEXT= <span class="string">&#x27;951e9bca-204f-11e8-b037-0127be441dc2:195&#x27;</span>/*!*/;</span><br><span class="line"><span class="comment"># at 395</span></span><br><span class="line"><span class="comment">#180412  9:52:43 server id 231144  end_log_pos 495 CRC32 0x439d8a47     Query   thread_id=69    exec_time=0     error_code=0</span></span><br><span class="line">SET TIMESTAMP=1523497963/*!*/;</span><br><span class="line">create database ghtest</span><br><span class="line">/*!*/;</span><br><span class="line"><span class="comment"># at 495</span></span><br><span class="line"><span class="comment">#180412  9:52:43 server id 231144  end_log_pos 543 CRC32 0x01f37d7c     GTID [commit=yes]</span></span><br><span class="line">SET @@SESSION.GTID_NEXT= <span class="string">&#x27;951e9bca-204f-11e8-b037-0127be441dc2:196&#x27;</span>/*!*/;</span><br><span class="line"><span class="comment"># at 543</span></span><br><span class="line"><span class="comment">#180412  9:52:43 server id 231144  end_log_pos 727 CRC32 0xd55dfb81     Query   thread_id=69    exec_time=0     error_code=0</span></span><br><span class="line">use `ghtest`/*!*/;</span><br><span class="line">SET TIMESTAMP=1523497963/*!*/;</span><br><span class="line">create table gh_ost_test (</span><br><span class="line">  <span class="built_in">id</span> int auto_increment,</span><br><span class="line">  i int not null,</span><br><span class="line">  primary key(<span class="built_in">id</span>)</span><br><span class="line">) auto_increment=1</span><br><span class="line">/*!*/;</span><br><span class="line">...</span><br><span class="line"><span class="comment"># at 727</span></span><br><span class="line"><span class="comment">#180412  9:52:43 server id 231144  end_log_pos 775 CRC32 0x68785572     GTID [commit=yes]</span></span><br><span class="line">SET @@SESSION.GTID_NEXT= <span class="string">&#x27;951e9bca-204f-11e8-b037-0127be441dc2:197&#x27;</span>/*!*/;</span><br><span class="line"><span class="comment"># at 775</span></span><br><span class="line"><span class="comment">#180412  9:52:43 server id 231144  end_log_pos 849 CRC32 0xc2c7a477     Query   thread_id=69    exec_time=0     error_code=0</span></span><br><span class="line">SET TIMESTAMP=1523497963/*!*/;</span><br><span class="line">BEGIN</span><br><span class="line">/*!*/;</span><br><span class="line"><span class="comment"># at 849</span></span><br><span class="line"><span class="comment">#180412  9:52:43 server id 231144  end_log_pos 906 CRC32 0x77d59f8e     Table_map: `ghtest`.`gh_ost_test` mapped to number 75</span></span><br><span class="line"><span class="comment"># at 906</span></span><br><span class="line"><span class="comment">#180412  9:52:43 server id 231144  end_log_pos 950 CRC32 0x731168d0     Write_rows: table id 75 flags: STMT_END_F</span></span><br><span class="line"><span class="comment">### INSERT INTO `ghtest`.`gh_ost_test`</span></span><br><span class="line"><span class="comment">### SET</span></span><br><span class="line"><span class="comment">###   @1=1</span></span><br><span class="line"><span class="comment">###   @2=0</span></span><br><span class="line"><span class="comment"># at 950</span></span><br><span class="line"><span class="comment">#180412  9:52:43 server id 231144  end_log_pos 981 CRC32 0xc7f39dd9     Xid = 253</span></span><br><span class="line">COMMIT/*!*/;</span><br></pre></td></tr></table></figure><h1 id="Redo-BINLOG-Changes"><a href="#Redo-BINLOG-Changes" class="headerlink" title="Redo BINLOG Changes"></a>Redo BINLOG Changes</h1><p>It’s useful for recovery operations by re-executing the output generated by mysqlbinlog, aka Point-in-Time (Incremental) Recovery. Rewrite the command in the last section to generate mysqlbinlog output with BINLOG statements. Each BINLOG statement contains a base 64-encoded string that server decodes to determine the data change indicated by the corresponding event. It requires the <a href="https://dev.mysql.com/doc/refman/5.6/en/privileges-provided.html#priv_super"><code>SUPER</code></a> privilege.</p><p>Some pratices below:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Output with BINLOG statements</span></span><br><span class="line">$ mysqlbinlog --base64-output=auto -v mysql-bin.000008</span><br><span class="line">...</span><br><span class="line"><span class="comment"># at 495</span></span><br><span class="line"><span class="comment">#180412  9:52:43 server id 231144  end_log_pos 543 CRC32 0x01f37d7c     GTID [commit=yes]</span></span><br><span class="line">SET @@SESSION.GTID_NEXT= <span class="string">&#x27;951e9bca-204f-11e8-b037-0127be441dc2:196&#x27;</span>/*!*/;</span><br><span class="line"><span class="comment"># at 543</span></span><br><span class="line"><span class="comment">#180412  9:52:43 server id 231144  end_log_pos 727 CRC32 0xd55dfb81     Query   thread_id=69    exec_time=0     error_code=0</span></span><br><span class="line">use `ghtest`/*!*/;</span><br><span class="line">SET TIMESTAMP=1523497963/*!*/;</span><br><span class="line">create table gh_ost_test (</span><br><span class="line">  <span class="built_in">id</span> int auto_increment,</span><br><span class="line">  i int not null,</span><br><span class="line">  primary key(<span class="built_in">id</span>)</span><br><span class="line">) auto_increment=1</span><br><span class="line">/*!*/;</span><br><span class="line"><span class="comment"># at 727</span></span><br><span class="line"><span class="comment">#180412  9:52:43 server id 231144  end_log_pos 775 CRC32 0x68785572     GTID [commit=yes]</span></span><br><span class="line">SET @@SESSION.GTID_NEXT= <span class="string">&#x27;951e9bca-204f-11e8-b037-0127be441dc2:197&#x27;</span>/*!*/;</span><br><span class="line"><span class="comment"># at 775</span></span><br><span class="line"><span class="comment">#180412  9:52:43 server id 231144  end_log_pos 849 CRC32 0xc2c7a477     Query   thread_id=69    exec_time=0     error_code=0</span></span><br><span class="line">SET TIMESTAMP=1523497963/*!*/;</span><br><span class="line">BEGIN</span><br><span class="line">/*!*/;</span><br><span class="line"><span class="comment"># at 849</span></span><br><span class="line"><span class="comment">#180412  9:52:43 server id 231144  end_log_pos 906 CRC32 0x77d59f8e     Table_map: `ghtest`.`gh_ost_test` mapped to number 75</span></span><br><span class="line"><span class="comment"># at 906</span></span><br><span class="line"><span class="comment">#180412  9:52:43 server id 231144  end_log_pos 950 CRC32 0x731168d0     Write_rows: table id 75 flags: STMT_END_F</span></span><br><span class="line"> </span><br><span class="line">BINLOG <span class="string">&#x27;</span></span><br><span class="line"><span class="string">67vOWhPohgMAOQAAAIoDAAAAAEsAAAAAAAEABmdodGVzdAALZ2hfb3N0X3Rlc3QAAgMDAACOn9V3</span></span><br><span class="line"><span class="string">67vOWh7ohgMALAAAALYDAAAAAEsAAAAAAAEAAgAC//wBAAAAAAAAANBoEXM=</span></span><br><span class="line"><span class="string">&#x27;</span>/*!*/;</span><br><span class="line"><span class="comment">### INSERT INTO `ghtest`.`gh_ost_test`</span></span><br><span class="line"><span class="comment">### SET</span></span><br><span class="line"><span class="comment">###   @1=1</span></span><br><span class="line"><span class="comment">###   @2=0</span></span><br><span class="line"><span class="comment"># at 950</span></span><br><span class="line"><span class="comment">#180412  9:52:43 server id 231144  end_log_pos 981 CRC32 0xc7f39dd9     Xid = 253</span></span><br><span class="line">COMMIT/*!*/;</span><br><span class="line">...</span><br><span class="line">  </span><br><span class="line"><span class="comment"># write binary log to a single file and then process the file</span></span><br><span class="line">$ mysqlbinlog --base64-output=auto -v --start-position=2302 mysql-bin.000008 | grep -v <span class="string">&quot;SESSION.GTID_NEXT&quot;</span> &gt; /tmp/mysql-bin-xxx.sql</span><br><span class="line"><span class="comment"># If the statements produced by mysqlbinlog may contain BLOB values, these may cause problems when mysql processes them. In this case, invoke mysql with the --binary-mode option.</span></span><br><span class="line">$ mysql -u xxx -pxxx &lt; /tmp/mysql-bin-xxx.sql</span><br><span class="line">  </span><br><span class="line"><span class="comment"># extract changes of a specific GTID range</span></span><br><span class="line">$ mysqlbinlog --base64-output=decode-rows -v --include-gtids=951e9bca-204f-11e8-b037-0127be441dc2:1-203 mysql-bin.000008</span><br></pre></td></tr></table></figure><p>Please note that I suppressed all <code>SET SESSION.GTID_NEXT</code> statements to make GTID generate automatically, alternatively you can reserve GTID_NEXT info and process them on another instance to make GTID changes exactly same as the instance the binary logs belong, like a replication client.</p><h1 id="Extract-SQL-Statements"><a href="#Extract-SQL-Statements" class="headerlink" title="Extract SQL Statements"></a>Extract SQL Statements</h1><p>Sometimes we need to extract the SQL statements as a source file, make changes on some sqls and then process on another instance. there isn’t a built-in way to perform that operation, a workaround as follows and we should extract :</p><ol><li>Get pseudo-SQL output by providing <em>–base64-output&#x3D;decode-row -v</em> options</li><li>Replace @N with their original column names</li><li>Remove all the <code>###</code> prefix of the statements</li></ol><p>Here is an example of extracting sqls from a specific table:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">$ mysqlbinlog --base64-output=decode-rows  -v mysql-bin.000008 |</span><br><span class="line">                sed -e <span class="string">&#x27;s/###   @1/      id/&#x27;</span> -e <span class="string">&#x27;s/###   @2/,     i/&#x27;</span> |</span><br><span class="line">                sed -e <span class="string">&#x27;s/### //g&#x27;</span> |</span><br><span class="line">                sed <span class="string">&#x27;/i=[0-9]*/s//&amp;;/&#x27;</span> |</span><br><span class="line">                sed -e <span class="string">&#x27;/^#/d&#x27;</span> -e <span class="string">&#x27;/^--$/d&#x27;</span></span><br><span class="line">...</span><br><span class="line">drop database <span class="keyword">if</span> exists ghtest</span><br><span class="line">/*!*/;</span><br><span class="line">SET @@SESSION.GTID_NEXT= <span class="string">&#x27;951e9bca-204f-11e8-b037-0127be441dc2:195&#x27;</span>/*!*/;</span><br><span class="line">SET TIMESTAMP=1523497963/*!*/;</span><br><span class="line">create database ghtest</span><br><span class="line">/*!*/;</span><br><span class="line">SET @@SESSION.GTID_NEXT= <span class="string">&#x27;951e9bca-204f-11e8-b037-0127be441dc2:196&#x27;</span>/*!*/;</span><br><span class="line">use `ghtest`/*!*/;</span><br><span class="line">SET TIMESTAMP=1523497963/*!*/;</span><br><span class="line">create table gh_ost_test (</span><br><span class="line">  <span class="built_in">id</span> int auto_increment,</span><br><span class="line">  i int not null,</span><br><span class="line">  primary key(<span class="built_in">id</span>)</span><br><span class="line">) auto_increment=1</span><br><span class="line">/*!*/;</span><br><span class="line">SET @@SESSION.GTID_NEXT= <span class="string">&#x27;951e9bca-204f-11e8-b037-0127be441dc2:197&#x27;</span>/*!*/;</span><br><span class="line">SET TIMESTAMP=1523497963/*!*/;</span><br><span class="line">BEGIN</span><br><span class="line">/*!*/;</span><br><span class="line">INSERT INTO `ghtest`.`gh_ost_test`</span><br><span class="line">SET</span><br><span class="line">      <span class="built_in">id</span>=1</span><br><span class="line">,     i=0;</span><br><span class="line">COMMIT/*!*/;</span><br><span class="line">...</span><br></pre></td></tr></table></figure><h1 id="Generate-Rollback-SQL"><a href="#Generate-Rollback-SQL" class="headerlink" title="Generate Rollback SQL"></a>Generate Rollback SQL</h1><p>Like talking on <strong>*Extract SQL Statements</strong>* section, if you want to reverse SQL on binary log files, we have to handle it by cases instead of generating them directly, at least not an easy way to do that now.</p><p>However, by the time we need to perform this operation, there’re approaches we can do after the SQL statements been extracted.</p><ol><li>Extract SQL Statement</li><li>replace different DML type for reversing</li></ol><p>Some examples:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># reverse INSERT events</span></span><br><span class="line">$ mysqlbinlog --base64-output=decode-rows -v mysql-bin.000010</span><br><span class="line">...</span><br><span class="line">BEGIN</span><br><span class="line">/*!*/;</span><br><span class="line"><span class="comment"># at 313</span></span><br><span class="line"><span class="comment">#180413 13:30:31 server id 231144  end_log_pos 371 CRC32 0x5f85e3c7     Table_map: `ghtest`.`gh_ost_test` mapped to number 78</span></span><br><span class="line"><span class="comment"># at 371</span></span><br><span class="line"><span class="comment">#180413 13:30:31 server id 231144  end_log_pos 419 CRC32 0x436c5ecf     Write_rows: table id 78 flags: STMT_END_F</span></span><br><span class="line"><span class="comment">### INSERT INTO `ghtest`.`gh_ost_test`</span></span><br><span class="line"><span class="comment">### SET</span></span><br><span class="line"><span class="comment">###   @1=6</span></span><br><span class="line"><span class="comment">###   @2=0</span></span><br><span class="line"><span class="comment"># at 419</span></span><br><span class="line"><span class="comment">#180413 13:30:31 server id 231144  end_log_pos 450 CRC32 0x2f186b8b     Xid = 694</span></span><br><span class="line">COMMIT/*!*/;</span><br><span class="line">...</span><br><span class="line">  </span><br><span class="line">$ mysqlbinlog --base64-output=decode-rows -v mysql-bin.000010 | grep -A 4 <span class="string">&#x27;### INSERT INTO&#x27;</span> |</span><br><span class="line">                sed -e <span class="string">&#x27;s/### INSERT INTO/DELETE FROM/&#x27;</span> -e <span class="string">&#x27;s/### SET/WHERE/&#x27;</span> |</span><br><span class="line">                sed -e <span class="string">&#x27;s/###   @1/      id/&#x27;</span> -e <span class="string">&#x27;s/###   @2/,     i/&#x27;</span> |</span><br><span class="line">                sed <span class="string">&#x27;/i=[0-9]*/s//&amp;;/&#x27;</span></span><br><span class="line">DELETE FROM `ghtest`.`gh_ost_test`</span><br><span class="line">WHERE</span><br><span class="line">      <span class="built_in">id</span>=6</span><br><span class="line">,     i=0;</span><br><span class="line">  </span><br><span class="line"><span class="comment"># Reverse DELETE events</span></span><br><span class="line">$ mysqlbinlog --base64-output=decode-rows -v mysql-bin.000010 | grep -A 4 <span class="string">&#x27;### DELETE FROM&#x27;</span> |</span><br><span class="line">              sed -e <span class="string">&#x27;s/### DELETE FROM/INSERT INTO/&#x27;</span> -e <span class="string">&#x27;s/### WHERE/SET/&#x27;</span>|</span><br><span class="line">              sed -e <span class="string">&#x27;s/###   @1/      id/&#x27;</span> -e <span class="string">&#x27;s/###   @2/,     i/&#x27;</span> |</span><br><span class="line">              sed <span class="string">&#x27;/i=[0-9]*/s//&amp;;/&#x27;</span></span><br><span class="line">INSERT INTO `ghtest`.`gh_ost_test`</span><br><span class="line">SET</span><br><span class="line">      <span class="built_in">id</span>=4</span><br><span class="line">,     i=1;</span><br><span class="line">  </span><br><span class="line"><span class="comment"># Reverse UPDATE events</span></span><br><span class="line">$ mysqlbinlog --base64-output=decode-rows -v mysql-bin.000010</span><br><span class="line">...</span><br><span class="line"><span class="comment"># at 498</span></span><br><span class="line"><span class="comment">#180413 13:30:47 server id 231144  end_log_pos 572 CRC32 0x002c4eae     Query   thread_id=80    exec_time=0 error_code=0</span></span><br><span class="line">SET TIMESTAMP=1523597447/*!*/;</span><br><span class="line">BEGIN</span><br><span class="line">/*!*/;</span><br><span class="line"><span class="comment"># at 572</span></span><br><span class="line"><span class="comment">#180413 13:30:47 server id 231144  end_log_pos 630 CRC32 0x1ec396c8     Table_map: `ghtest`.`gh_ost_test` mapped to number 78</span></span><br><span class="line"><span class="comment"># at 630</span></span><br><span class="line"><span class="comment">#180413 13:30:47 server id 231144  end_log_pos 692 CRC32 0x8a24569e     Update_rows: table id 78 flags: STMT_END_F</span></span><br><span class="line"><span class="comment">### UPDATE `ghtest`.`gh_ost_test`</span></span><br><span class="line"><span class="comment">### WHERE</span></span><br><span class="line"><span class="comment">###   @1=3</span></span><br><span class="line"><span class="comment">###   @2=2</span></span><br><span class="line"><span class="comment">### SET</span></span><br><span class="line"><span class="comment">###   @1=3</span></span><br><span class="line"><span class="comment">###   @2=3</span></span><br><span class="line"><span class="comment"># at 692</span></span><br><span class="line"><span class="comment">#180413 13:30:47 server id 231144  end_log_pos 723 CRC32 0x7bcddc40     Xid = 695</span></span><br><span class="line">COMMIT/*!*/;</span><br><span class="line">...</span><br><span class="line">  </span><br><span class="line">$ mysqlbinlog --base64-output=decode-rows -v mysql-bin.000010 | grep -A 8 <span class="string">&#x27;### UPDATE&#x27;</span> |</span><br><span class="line">              sed -e <span class="string">&#x27;s/### UPDATE/UPDATE/&#x27;</span> | sed -e <span class="string">&#x27;s/### SET/WHERE/&#x27;</span> | sed -e <span class="string">&#x27;s/### WHERE/SET/&#x27;</span> |</span><br><span class="line">              sed -e <span class="string">&#x27;s/###   @1/      id/&#x27;</span> -e <span class="string">&#x27;s/###   @2/,     i/&#x27;</span> |</span><br><span class="line">              sed  -e <span class="string">&#x27;/WHERE/&#123;n;n;s|$|;|&#125;&#x27;</span></span><br><span class="line">...</span><br><span class="line">UPDATE `ghtest`.`gh_ost_test`</span><br><span class="line">SET</span><br><span class="line">      <span class="built_in">id</span>=3</span><br><span class="line">,     i=2</span><br><span class="line">WHERE</span><br><span class="line">      <span class="built_in">id</span>=3</span><br><span class="line">,     i=3;</span><br><span class="line">...</span><br></pre></td></tr></table></figure><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><p><a href="https://dev.mysql.com/doc/refman/5.6/en/mysqlbinlog.html">https://dev.mysql.com/doc/refman/5.6/en/mysqlbinlog.html</a></p><p><a href="https://dev.mysql.com/doc/refman/5.6/en/mysqlbinlog-row-events.html">https://dev.mysql.com/doc/refman/5.6/en/mysqlbinlog-row-events.html</a></p><p><a href="https://dev.mysql.com/doc/refman/5.6/en/point-in-time-recovery.html">https://dev.mysql.com/doc/refman/5.6/en/point-in-time-recovery.html</a></p><p><a href="https://dev.mysql.com/doc/refman/5.6/en/mysqlbinlog-backup.html">https://dev.mysql.com/doc/refman/5.6/en/mysqlbinlog-backup.html</a></p>]]></content>
    
    
    <summary type="html">&lt;p&gt;In case of Database Recovery after unexpected data corruption, list some commonly used scenarios of &lt;em&gt;mysqlbinlog&lt;/em&gt; for processing binary log files.&lt;/p&gt;
&lt;h1 id=&quot;Display-Row-Events&quot;&gt;&lt;a href=&quot;#Display-Row-Events&quot; class=&quot;headerlink&quot; title=&quot;Display Row Events&quot;&gt;&lt;/a&gt;Display Row Events&lt;/h1&gt;&lt;p&gt;Convert binary events to SQL statements, DDL output will be displayed as a raw statement, DML output will be presented as lines beginning with &lt;code&gt;###&lt;/code&gt;, those are “pseudo-SQL” statements which are not executable.&lt;/p&gt;
&lt;p&gt;For DML pseudo-SQL statements, they do not correspond exactly to the original SQL statements that generated the events, The original column names are lost and replaced by &lt;code&gt;@*N*&lt;/code&gt;, where &lt;em&gt;N&lt;/em&gt; is a column number. &lt;/p&gt;
&lt;p&gt;Also if you are using multi-character set data, those character set information is not available in the display.&lt;/p&gt;</summary>
    
    
    
    <category term="workspace" scheme="https://beanbee.github.io/categories/workspace/"/>
    
    
    <category term="MySQL" scheme="https://beanbee.github.io/tags/MySQL/"/>
    
  </entry>
  
</feed>
